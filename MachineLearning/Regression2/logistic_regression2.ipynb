{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio en lineas de frontera (boundary lines): Regresion Logística\n",
    "\n",
    "## Introducción:\n",
    "\n",
    "En este ejercicio usted implementarà la regresión logística para dos conjuntos de datos. Antes de comenzar le recomiendo que mires los videos de clase y las notas de clase. \n",
    "\n",
    "Toda la información que necesita para esta tarea está contenida en este cuaderno, lo mismo que el \n",
    "código que necesita implementar. \n",
    "\n",
    "Las librerías (módulos) que necesitará son ```numpy``` y ```matplotlib```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para el manejo de caminos\n",
    "import os\n",
    "\n",
    "# para la parte numérica\n",
    "import numpy as np\n",
    "\n",
    "# para gràficas\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# optimización\n",
    "from scipy import optimize\n",
    "\n",
    "# incluye la gráfica en este cuaderno\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Regresión logística\n",
    "En esta sección usted debe construir un modelo para decidir si un estudiante es admitido a la unviersidad. Suponga que usted es el jefe de admisiones y registro de la universidad y desea determinar si los aplicantes deben ser admitidos basados en 2 exàmenes. Usted tiene la historia de los datos de los aplicantes de años anteriores, con los cuales puede entrenar su regresión logística. Para cada estudiante usted tiene los resultados de dos exámentes de admisión. Su tarea es construir un modelo de clasificación que estima la probabilidad de admisión basándose en los dos exámenes.\n",
    "\n",
    "En la siguiente celda se cargan los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar datos\n",
    "# las primeras dos columnas tienen los resultados de los exámenes\n",
    "# la tercera contiene las etiquetas\n",
    "data = np.loadtxt(os.path.join('Data', 'ex2data1.txt'), delimiter=',')\n",
    "X, y = data[:, 0:2], data[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Visualización de los datos\n",
    "\n",
    "Antes de implementar cualquier tarea de aprendizaje es útil visualizar los datos, siempre que sea posible. Mostramos los datos en gràficos en 2 dimensiones. Debes completar el código en ```plotData``` de forma que los ejes son las calificaciones de los dos exámenes y los resultados (positivo o negativo) se muestran con marcadores. \n",
    "\n",
    "Para que puedas practicar el software de graficación le dejamos espacio para implementar la función ```plotData```.   Sin embargo esto no lo califico, más abajo incluyo la implementación para que la compare\n",
    "con su trabajo. Si decides copiar y pegar de mi implementación abajo, asegúrese de aprender los comandos\n",
    "de ```matplotlib``` y ```numpy```. \n",
    "\n",
    "\n",
    "```python\n",
    "# Encuentre los índices de muestras positivas y negativas\n",
    "pos = y == 1\n",
    "neg = y == 0\n",
    "\n",
    "# Grafique los ejemplos\n",
    "pyplot.plot(X[pos, 0], X[pos, 1], 'k*', lw=2, ms=10)\n",
    "pyplot.plot(X[neg, 0], X[neg, 1], 'ko', mfc='y', ms=8, mec='k', mew=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(X, y):\n",
    "    \"\"\"\n",
    "    Grafique los puntos X y y.  Los puntos los debe graficar\n",
    "    con * para la muestras positivas y o para las muestras negativas.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : arreglo de floats\n",
    "        Una matriz  Mx2 que representa los datos. \n",
    "    \n",
    "    y : arreglo de floats\n",
    "        Datos con las etiquetas. Un vector de tamaño (M, ).\n",
    "    \n",
    "    Instrucciones\n",
    "    ------------\n",
    "    Grafique las muestras positivas y negativas en una figura 2D, usando\n",
    "    la opcion 'k*' para las muestras positivas y 'ko' para las muestras \n",
    "    negativas. \n",
    "    \"\"\"\n",
    "    # nueva figura\n",
    "    fig = pyplot.figure()\n",
    "\n",
    "    # ====================== SU CÒDIGO ACÁ ======================\n",
    "\n",
    "    \n",
    "    # ============================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamemos la funcion para cargar la figura con los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(X, y)\n",
    "# etiquetas a los ejes\n",
    "pyplot.xlabel('Exam 1 score')\n",
    "pyplot.ylabel('Exam 2 score')\n",
    "pyplot.legend(['Admitted', 'Not admitted'])\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "### 1.2 Implementación\n",
    "\n",
    "#### 1.2.1 Ejercicio de calentamiento: funciòn sigmoid logística\n",
    "\n",
    "Recuerde, antes de implementar la función de costo, que la hipótesis se definine como:\n",
    "$$ h_\\theta(x) = g(\\theta^T x)$$\n",
    "\n",
    "donde la funciòn $g$ es la sigmoid logística definida como:\n",
    "\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$.\n",
    "\n",
    "Su primer paso es implementar esta función para que se pueda usar en\n",
    "el resto del programa. Trate de probarla par algunos valores llamando\n",
    "```sigmodi(x)``` en una nueva celda. Para valores positivos grandes de `x`,\n",
    "la función sigmoid debería estar cerca a 1, mientras que para valores negativos\n",
    "grandes debería estar cerca a 0. El valor ```sigmoid(0)``` debería ser\n",
    "exactamente 0.5. Su código debería trabajar también para vectores y matrices.\n",
    "**Para el caso en que el argumento sea una matriz, la funciòn sigmoid debe\n",
    "operar elemento-por-elemento. \n",
    "<a id=\"sigmoid\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    evalue la funcion logístic sigmoid con argumento z\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : arreglo de floats\n",
    "        Puede ser un vector o una matriz 2D.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    g : arreglo de floats\n",
    "        Debe tener la misma estructura de z, dado que la \n",
    "        operación se da elemento-por-elemento.\n",
    "        \n",
    "    Instrucciones:\n",
    "    ------------\n",
    "    Calcule la función logística sigmoid para cada valor z\n",
    "    sea este escalar, vector, o matriz.\n",
    "    \"\"\"\n",
    "    \n",
    "    # convierta la entrada en un arreglo en numpy\n",
    "    z = np.array(z)\n",
    "    \n",
    "    # Necesita retornar las siguientes variables correctamente\n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    # ====================== SU CÓDIGO ACÀ ======================\n",
    "\n",
    "    \n",
    "\n",
    "    # =============================================================\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda evalúa la función logística sigmoid en ```z=0```. Deberìa obtener 0.5. Puede experimentar\n",
    "con otros valores de ```z```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruebe su implementación acá.\n",
    "z = 0\n",
    "g = sigmoid(z)\n",
    "\n",
    "print('g(', z, ') = ', g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "#### 1.2.2 Función de costo y su gradiente\n",
    "\n",
    "A continuación usted debe implementar la función de costo  para la regresión logística.\n",
    "Antes de seguir non olvide agregar el intercepto X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construya la matriz apropiadamente agregando unos para el intercepto\n",
    "m, n = X.shape\n",
    "\n",
    "# Agrega el intercepto\n",
    "X = np.concatenate([np.ones((m, 1)), X], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora debe completar la implementación de la función de costo ```costFunction``` la cual retorna la funciòn de costo y su gradiente. Recuerda que la función de costo para la regresión logística está dada por:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ -y^{(i)} \\log\\left(h_\\theta\\left( x^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - h_\\theta\\left( x^{(i)} \\right) \\right) \\right]$$\n",
    "\n",
    "y el gradiente de la función de costo es un vector de la misma longitud de $\\theta$ donde la\n",
    "componente $j$ para $j=0,1, \\cdots, n$ se define como\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} $$\n",
    "\n",
    "Note que, aunque este gradiente se ve idèntico la del gradiente de la regresión lineal, la fòrmula\n",
    "es diferente por que la regresión logística y lineal tienen hipótesis diferentess $h(\\theta, x)$.\n",
    "\n",
    "<a id=\"costFunction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(theta, X, y):\n",
    "    \"\"\"\n",
    "    calcule la función de costo para la regresión logística\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    theta:  arreglo de floats\n",
    "        Los parámetros de la regresión logística son un vector\n",
    "        de tamaño (n+1, ).\n",
    "\n",
    "    \n",
    "    X : arreglo de floats\n",
    "        Los datos de entrada tienen tamaño (n x n +1 ) donde m es\n",
    "        el nùmero de puntos de entrada y n es el número de atributos.\n",
    "        Se asume que el intercepto ya se ha agregado a la matriz de datos.\n",
    "    \n",
    "    \n",
    "\n",
    "    y : arreglo de floats\n",
    "        Las etiquetas para la entrada. El tamaño del vector es (m, ).\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    J : float\n",
    "        El valor de la funciòn de costo\n",
    "        \n",
    "    \n",
    "    grad : arreglo de floats\n",
    "        Un vector de tamaño (n+1, ) con el gradiente de la función de costo,\n",
    "        con respecto a theta.\n",
    "       \n",
    "    Instructiones\n",
    "    ------------\n",
    "    Compute the cost of a particular choice of theta. You should set J to \n",
    "    the cost. Compute the partial derivatives and set grad to the partial\n",
    "    derivatives of the cost w.r.t. each parameter in theta.\n",
    "    \"\"\"\n",
    "    # Inicialice algunos valores ùtiles\n",
    "    m = y.size  # nùmero de muestras de entrenamiento\n",
    "    \n",
    "    # Necesita retornar las siguientes variables correctamente.\n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    # ====================== SU CÓDIGO ACÁ ======================\n",
    "\n",
    "    \n",
    "    \n",
    "    # =============================================================\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez termine debe llamar su ```costFunction``` usando dos pruebas para $\\theta$\n",
    "en la próxima celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicialice los parámetros\n",
    "initial_theta = np.zeros(n+1)\n",
    "\n",
    "cost, grad = costFunction(initial_theta, X, y)\n",
    "\n",
    "print('Cost at initial theta (zeros): {:.3f}'.format(cost))\n",
    "print('Expected cost (approx): 0.693\\n')\n",
    "\n",
    "print('Gradient at initial theta (zeros):')\n",
    "print('\\t[{:.4f}, {:.4f}, {:.4f}]'.format(*grad))\n",
    "print('Expected gradients (approx):\\n\\t[-0.1000, -12.0092, -11.2628]\\n')\n",
    "\n",
    "# calcule y muestre la función de costo y el gradiente con theta no nulo\n",
    "test_theta = np.array([-24, 0.2, 0.2])\n",
    "cost, grad = costFunction(test_theta, X, y)\n",
    "\n",
    "print('Cost at test theta: {:.3f}'.format(cost))\n",
    "print('Expected cost (approx): 0.218\\n')\n",
    "\n",
    "print('Gradient at test theta:')\n",
    "print('\\t[{:.3f}, {:.3f}, {:.3f}]'.format(*grad))\n",
    "print('Expected gradients (approx):\\n\\t[0.043, 2.566, 2.647]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 parámetros de aprendizaje metiante el uso de`scipy.optimize`\n",
    "En una tarea anterior usted encontró los parámetros óptimos de un modelo\n",
    "de regresión lineal mediante el uso del descenso con gradiente. Usted escribió la\n",
    "función de costo y calculó el gradiente, luego usó el gradiente para bajar al mínimo.\n",
    "En este caso, en vez de usar los pasos de descenso de gradiente, usted usará\n",
    "el módulo [`scipy.optimize` module](https://docs.scipy.org/doc/scipy/reference/optimize.html). SciPy es una librería numérica de `python`. Esta provee un módulo\n",
    "de optimización para encontrar una raíz mediante optimización. En  `scipy 1.0`, la función `scipy.optimize.minimize` es el método de optimizacion para problemas con o sin restricciones. \n",
    "\n",
    "Para el caso de regresión logística, usted debe optimizar la función de costo\n",
    " $J(\\theta)$ con parámetros $\\theta$. Concretamente, usted debe usar la función\n",
    "  `optimize.minimize` para entrontrar los parámetros  $\\theta$ de la regresión \n",
    "de costo logística dados los datos \"X\" y \"y\". Debe pasar a la función  `optimize.minimize` los siguientes parámetros\n",
    "\n",
    "- `costFunction`: La función de costo , dados los datos de entrenamiento y un $\\theta$ particular para los datos (X, y). Es importante notar que solo pasamos el nombre de la función sin paréntesis. Esto indica que solo pasamos una referencia a la función, y no  el resultado de su evaluación. \n",
    "\n",
    "- `initial_theta`:  El valor inicial de los parámetros de optimización \n",
    "\n",
    "- `(X, y)`: Estos son argumentos adicionales para a función de costo. \n",
    "\n",
    "- `jac`: Un indicador de si la función retorna el Jacobiano (gradiente) junto con el valor de costo (True)\n",
    "\n",
    "\n",
    "- `method`: Método de optimización que usa el algoritmo.\n",
    "\n",
    "- `options`: opciones adicionales las cuales pueden ser esfecíficas al método de optimización. En lo que sigue solo le decimos al algoritmo el máximo número de iteraciones que se pueden ejecutar. \n",
    "\n",
    "If ya completó la  `costFunction` correctamente , `optimize.minimize` dbe converger\n",
    "a los parámetros adecuados de optimización y retornar los valores finales de la\n",
    "función de costo lo mismo que $\\theta$.   Note que mediante el uso  `optimize.minimize`, usted evita la escritura de ciclos, o definir una tasa de aprendizaje como lo hace para el descenso con gradiente. Esto lo hacer el \n",
    "`optimize.minimize`: usted solo necesita suministrar una función que calcula el costo y su gradiente. \n",
    "\n",
    "Enseguida tenemos el codigo escrito que llama  `optimize.minimize` con los argumentos\n",
    "correctos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limitar el número de iteraciones a 400\n",
    "options= {'maxiter': 400}\n",
    "\n",
    "# consulte la documentación de scipy en optimize.minimize para la descripción\n",
    "# de los diferentes parámetros. \n",
    "# a función retorna un objeto  `OptimizeResult`\n",
    "\n",
    "# Usamos un algoritmo truncado de Newton para lo optimización que\n",
    "# es equivalente a la función de MATLAB fminunc\n",
    "# ver  https://stackoverflow.com/questions/18801002/fminunc-alternate-in-numpy\n",
    "res = optimize.minimize(costFunction,\n",
    "                        initial_theta,\n",
    "                        (X, y),\n",
    "                        jac=True,\n",
    "                        method='TNC',\n",
    "                        options=options)\n",
    "\n",
    "\n",
    "# la propiedad de la función  `OptimizeResult` retorna\n",
    "# el valor de la costFunction para el valor optimizado de theta\n",
    "cost = res.fun\n",
    "\n",
    "# el valor óptimo de theta esta en la propiedad \"x\"\n",
    "theta = res.x\n",
    "\n",
    "# imprima theta\n",
    "print('Cost at theta found by optimize.minimize: {:.3f}'.format(cost))\n",
    "print('Expected cost (approx): 0.203\\n');\n",
    "\n",
    "print('theta:')\n",
    "print('\\t[{:.3f}, {:.3f}, {:.3f}]'.format(*theta))\n",
    "print('Expected theta (approx):\\n\\t[-25.161, 0.206, 0.201]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez la función  `optimize.minimize` finalice, debemos usar el valor final de $\\theta$ para visualizar la frontera de decisión en los datos de entrenamiento\n",
    "como se muestra en a siguiente Figura. \n",
    "\n",
    "![](Figures/decision_boundary1.png)\n",
    "\n",
    "Pare esto escribimos la función `plotDecisionBoundary` que grafica la frontera\n",
    "de decisión. Sugerimos que revisen el código `plotDecisionBoundary` para ver como\n",
    "se grafica esta frontera usando los valores de  $\\theta$. Esta función la encontrará en `utils.py` que viene con esta tarea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafique la frontera de decisión \n",
    "utils.plotDecisionBoundary(plotData, theta, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "#### 1.2.4 Evaluación de la regresión logística. \n",
    "\n",
    "Luego de aprender los parámetros, usted puede usar el modelo para predecir si algún alumno puede o no ser admitido. Para un estudiante con una nota de 45 en el primer\n",
    "examen y 85 en el segundo examen, debe encontrar una probabilidad de admisión de 0.776. Otra forma de evaluar la calidad de los parámetros que encontró es observando que tan bien el modelo aprendido predice los datos de entrenamiento. \n",
    "En esta parte, su tarea es completr el código de la función `predict`. Esta función \n",
    "predice \"1\" o \"0\" dados los datos y el parámetro de aprendizaje $\\theta$. \n",
    "\n",
    "\n",
    "<a id=\"predict\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    \"\"\"\n",
    "    predicción de las etiquetas 0 o 1 usando el modelo aprendido.\n",
    "    Calcula las predicciones para X usando un umbral de 0.5\n",
    "    (es decir, si sigmoid(theta.T*x)  >= 0.5, prediga 1)\n",
    "    \n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    theta : arreglo de floats\n",
    "        Parámetros para la regresión logística. Un vector de tamaño (n+1,).\n",
    "    \n",
    "    X : arreglo de floats\n",
    "        Los datos usados para hacer la predicción. Las filas son el número \n",
    "        de puntos (datos), las columnas son el número de atributos (features).\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    p : arreglo de floats\n",
    "        Predicciones 0 o 1 para cada fila de X.\n",
    "    \n",
    "    Instrucciones\n",
    "    ------------\n",
    "    Complete el código a continuación para calcular las predicciones usando\n",
    "    los parámetros de regresión logística aprendidos. El vector p debe ser\n",
    "    de 0's y 1's. \n",
    "    \"\"\"\n",
    "    m = X.shape[0] # Número de muestras de entrenamiento\n",
    "\n",
    "    # debe retornar los valores a continuación correctamente. \n",
    "    p = np.zeros(m)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "\n",
    "    \n",
    "    \n",
    "    # ============================================================\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de completar el código en `predict`, procedemos a reportar el \"accuracy\" de su\n",
    "clasificador mediante el porcentaje de puntos correctamente predichos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción de la probabilidad para un estudiante con nota 45\n",
    "# en el primer examen y 85 en el segundo. \n",
    "\n",
    "prob = sigmoid(np.dot([1, 45, 85], theta))\n",
    "print('For a student with scores 45 and 85,'\n",
    "      'we predict an admission probability of {:.3f}'.format(prob))\n",
    "print('Expected value: 0.775 +/- 0.002\\n')\n",
    "\n",
    "# calculo del \"accuracy\" en los datos de entrenamiento. \n",
    "p = predict(theta, X)\n",
    "print('Train Accuracy: {:.2f} %'.format(np.mean(p == y) * 100))\n",
    "print('Expected accuracy (approx): 89.00 %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Regresión logística regularizada\n",
    "\n",
    "En esta parte de su tarea usted implementará la regresi{on loística regularizada para\n",
    "predecir si los microchips de una planta de fabricación pasan el control de calidad (Quality Assurance QA). Durante el QA, cada microchip pasa varios estados que aseguran su funcionamiento correcto. \n",
    "\n",
    "Asuma que su gerente de producción y usted tienen los resultados de la pruebas para algunos microchips\n",
    "en dos conjuntos.  De estos dos conjuntos de pruebas usted debe determinar si los microchips deberían \n",
    "ser aceptados o rechazados. Para ayudarle en la decisión, usted tiene un conjunto de datos del pasado, sobre los cuales debe construir su modelo de regresión logística. \n",
    "\n",
    "Comience por cargar el archivo CSV. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue los datos\n",
    "# las dos primeras columnas contienen los valores de X\n",
    "# la tercera columna tiene los valores de y\n",
    "\n",
    "data = np.loadtxt(os.path.join('Data', 'ex2data2.txt'), delimiter=',')\n",
    "X = data[:, :2]\n",
    "y = data[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualización de los datos\n",
    "De la misma forma que en los ejercicios previos, la función `plotData` se usa para generar la figura,\n",
    "donde los ejes son las dos calificaciones, y los valores positivos (y=1, aceptado) y\n",
    "negativo (y=0, rechazado) se muestran con marcas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(X, y)\n",
    "# etiquetas y leyenda\n",
    "pyplot.xlabel('Microchip Test 1')\n",
    "pyplot.ylabel('Microchip Test 2')\n",
    "\n",
    "# especificados en orden\n",
    "pyplot.legend(['y = 1', 'y = 0'], loc='upper right')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La figura de arriba muestra que nuestro conjunto no puede ser separado en muestras positivas y negativas por una línea recta.  De esta forma, una aplicación directa y simple de regresión logística no funciona.\n",
    "Necesitamos un argumento de la hipótesis no lineal. \n",
    "\n",
    "\n",
    "### 2.2 Mapeo de atributos (feature mapping)\n",
    "Una forma mejor para ajustar los datos es mediante el uso de atributos para cada punto.\n",
    "En la función  `mapFeature` definida en el archivo  `utils.py`  mapea los atributos en polinomios\n",
    "en 2 variables hasta el grado 6. \n",
    "\n",
    "\n",
    "$$ \\text{mapFeature}(x) = \\begin{bmatrix} 1 & x_1 & x_2 & x_1^2 & x_1 x_2 & x_2^2 & x_1^3 & \\dots & x_1 x_2^5 & x_2^6 \\end{bmatrix}^T $$\n",
    "\n",
    "Como resultado de este mapeo, nuestro vector de dos atributos (los resultados de las dos pruebas de QA) se transforman en un vector de 28 dimensiones. Una clasificación logística entrenada en este espacio de altas dimensiones produce una frontera de decisión más compleja y aparece como no lineal en una gráfica 2-dimensional. \n",
    "\n",
    "Mientras que este mapeo permite construir clasificadores mas costosos, es mas sensible a sobreajuste.\n",
    "En lo que sigue del ejercicio usted implementará la regresión logística regularizada para ajustar\n",
    "los datos y verificar visualmente como la regularización ayuda a combatir el problema de sobreajuste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note que mapFeature agrega la columna de unos que se encarga del intercepto\n",
    "X = utils.mapFeature(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "### 2.3 Función de costo y su gradiente\n",
    "Ahora usted implementará la parte del código que calcula la función de costo y su gradiente para una regresión logística regularizada. \n",
    "\n",
    "Recuerde que la función de costo para la regresión logística regularizada está dada por:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\left[ -y^{(i)}\\log \\left( h_\\theta \\left(x^{(i)} \\right) \\right) - \\left( 1 - y^{(i)} \\right) \\log \\left( 1 - h_\\theta \\left( x^{(i)} \\right) \\right) \\right] + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\theta_j^2 $$\n",
    "\n",
    "Note que usted no necesita regularizar el parámetro $\\theta_0$. El gradiente de la función de\n",
    "costo es un vector donde el elemento $j$-ésimo está definido como:\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left(x^{(i)}\\right) - y^{(i)} \\right) x_j^{(i)} \\qquad \\text{for } j =0 $$\n",
    "\n",
    "$$ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\left( \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left(x^{(i)}\\right) - y^{(i)} \\right) x_j^{(i)} \\right) + \\frac{\\lambda}{m}\\theta_j \\qquad \\text{for } j \\ge 1 $$\n",
    "<a id=\"costFunctionReg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunctionReg(theta, X, y, lambda_):\n",
    "    \"\"\"\n",
    "    Calcule el costo  y su gradiente para la regresión logística regularizada. \n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    theta : arreglo de floats\n",
    "        Parámetros de la regresión logística. Un vector de tamaño (n, ).  \n",
    "        n es el número de atributos (features) incluyendo el intercepto.\n",
    "        Si ya mapeamos los atributos a un polinomio, entonfes n es el total\n",
    "        de atributos (términos) en el polinomio. \n",
    "       \n",
    "    \n",
    "    X : arreglo de floats\n",
    "        Los datos tienen tamaño (m x n). m es el número de muestras, y \n",
    "        n es el número de atributos (luego del mapeo).\n",
    "        \n",
    "    \n",
    "    y : arreglo de floats\n",
    "        Las etiquetas de los datos. Un vector de tamaño (m, ).\n",
    "    \n",
    "    lambda_ : float\n",
    "        Parámetro de regularización. \n",
    "    \n",
    "    Returna\n",
    "    -------\n",
    "    J : float\n",
    "        función de costo regularizada\n",
    "    \n",
    "    grad : vector de floats\n",
    "        Un vector de tamaño (n, ) con el gradiente de la función de costo\n",
    "        regularizada con respecto a theta, en el valor corriente de theta. \n",
    "        A vector of shape (n, ) which is the gradient of the cost\n",
    "        function with respect to theta, at the current values of theta.\n",
    "    \n",
    "    Instrucciones\n",
    "    ------------\n",
    "    Calcule el costo \"J\" para un valor particular de theta. \n",
    "    Calcule las derivadas parciales que conforman el gradiente\n",
    "    \"grad\" para cada parámetro theta. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicialización de valores\n",
    "    m = y.size  # número de muestras de entrenamiento\n",
    "\n",
    "    # necesita retornar las dos variables a continuación correctamente\n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    # ===================== SU CÓDIGO ACÁ ======================\n",
    "\n",
    "    \n",
    "    \n",
    "    # =============================================================\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez usted complete la función de costo  `costFunctionReg`, la debe llamar abajo usando valores iniciales de $\\theta$ de puros unos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicialice los parámetros\n",
    "initial_theta = np.zeros(X.shape[1])\n",
    "\n",
    "# asigne 1 a lambda\n",
    "# no use \"lambda\" como una variable en python\n",
    "# por que es una palabra clave\n",
    "lambda_ = 1\n",
    "\n",
    "# calcule y muestre la función de costo y su gradiente para la\n",
    "# regresión logística regularizada\n",
    "cost, grad = costFunctionReg(initial_theta, X, y, lambda_)\n",
    "\n",
    "print('Cost at initial theta (zeros): {:.3f}'.format(cost))\n",
    "print('Expected cost (approx)       : 0.693\\n')\n",
    "\n",
    "print('Gradient at initial theta (zeros) - first five values only:')\n",
    "print('\\t[{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}]'.format(*grad[:5]))\n",
    "print('Expected gradients (approx) - first five values only:')\n",
    "print('\\t[0.0085, 0.0188, 0.0001, 0.0503, 0.0115]\\n')\n",
    "\n",
    "\n",
    "# Calcule y muestre el costo y su gradiente\n",
    "# con theta todos unos y lambda=10 \n",
    "test_theta = np.ones(X.shape[1])\n",
    "cost, grad = costFunctionReg(test_theta, X, y, 10)\n",
    "\n",
    "print('------------------------------\\n')\n",
    "print('Cost at test theta    : {:.2f}'.format(cost))\n",
    "print('Expected cost (approx): 3.16\\n')\n",
    "\n",
    "print('Gradient at test theta - first five values only:')\n",
    "print('\\t[{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}]'.format(*grad[:5]))\n",
    "print('Expected gradients (approx) - first five values only:')\n",
    "print('\\t[0.3460, 0.1614, 0.1948, 0.2269, 0.0922]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Aprendizaje de parámetros usando `scipy.optimize.minimize`\n",
    "\n",
    "Similarmente, usted debe usar `optimize.minimize` para aprender los parámetros óptimos $\\theta$.\n",
    "Si usted ya completó la función de costo y su gradiente para la regresión logística regularizada\n",
    "(`costFunctionReg`) correctamente, usted debería ser capaz de resolver la parte siguiente para\n",
    "aprender $\\theta$ usando  `optimize.minimize`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Grafique la frontera de decisión.\n",
    "\n",
    "Para ayudarle a visualizar su modelo aprendido por este clasificador, le\n",
    "suminstramos la función  `plotDecisionBoundary` la cual grafica la frontera\n",
    "de decisión no lineal, que separa los puntos aceptados y=1 de los no\n",
    "aceptados y=0. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.5 Optional no se califica\n",
    "\n",
    "En esta parte del ejercicio usted debe tratar varios parametros de regularización\n",
    "para ver como la regularizacion previene el \"overfitting\"\n",
    "\n",
    "Note los cambios en la frontera de decisión a medida que varía $\\lambda$. Con\n",
    "un $\\lambda$ pequeño debe observar que el calsificator de ajusta a casi todas\n",
    "las muestras de entrenamiento, pero dibuja una frontera complicada, con sobreajuste (overfitting) a los datos. Observe las siguientes figuras para valores diferentes\n",
    "de $\\lambda$.\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">\n",
    "            No regularization (overfitting)<img src=\"Figures/decision_boundary3.png\">\n",
    "        </td>        \n",
    "        <td style=\"text-align:center\">\n",
    "            Decision boundary with regularization\n",
    "            <img src=\"Figures/decision_boundary2.png\">\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            Decision boundary with too much regularization\n",
    "            <img src=\"Figures/decision_boundary4.png\">\n",
    "        </td>        \n",
    "    <tr>\n",
    "</table>\n",
    "\n",
    "No hay una buena frontera de decision: por ejemplo, sse predice que el punto\n",
    " $x = (−0.25, 1.5)$  se acepta $(y=1)$, lo que parece incorrecto para los datos\n",
    " de entrenamiento. Con valores de $\\lambda$ mayores debería ver una gráfica con\n",
    " una frontera de decisión más simple que separa los positivos de los negativos más o menos bien. Sin embargo, si $\\lambda$ se usa con un valor muy grande, no se tiene \n",
    " un buen ajuste en la frontera de decisición y produce sub-ajuste (underfitting).\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicialice los parametros\n",
    "initial_theta = np.zeros(X.shape[1])\n",
    "\n",
    "# use lambda=1 para esta pruebta\n",
    "lambda_ = 1.00\n",
    "\n",
    "# opciones para el optimizador\n",
    "options= {'maxiter': 100}\n",
    "\n",
    "res = optimize.minimize(costFunctionReg,\n",
    "                        initial_theta,\n",
    "                        (X, y, lambda_),\n",
    "                        jac=True,\n",
    "                        method='TNC',\n",
    "                        options=options)\n",
    "\n",
    "# el OptimizeResult retorna el valor de la funcion de\n",
    "# costo para un valor de theta optimizado\n",
    "cost = res.fun\n",
    "\n",
    "# el valor optimizado de theta\n",
    "theta = res.x\n",
    "\n",
    "utils.plotDecisionBoundary(plotData, theta, X, y)\n",
    "pyplot.xlabel('Microchip Test 1')\n",
    "pyplot.ylabel('Microchip Test 2')\n",
    "pyplot.legend(['y = 1', 'y = 0'])\n",
    "pyplot.grid(False)\n",
    "pyplot.title('lambda = %0.2f' % lambda_)\n",
    "\n",
    "# calcule la precision\n",
    "p = predict(theta, X)\n",
    "\n",
    "print('Train Accuracy: %.1f %%' % (np.mean(p == y) * 100))\n",
    "print('Expected accuracy (with lambda = 1): 83.1 % (approx)\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
