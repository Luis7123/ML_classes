{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio de programación 7:\n",
    "# Agrupamiento K-means  y Análisis de Componentes Principales \n",
    "\n",
    "## Introducción\n",
    "\n",
    "En este ejericio, implementará el algoritmo de agrupamiento K-means y lo aplicará en la compresión de imágenes.\n",
    "En la segunda parte, usará análisis de componentes principales para encontrar una representación en baja dimensión\n",
    "de imágenes de caras. \n",
    "\n",
    "Toda la información que necesita para resolver este ejercicio está contenida en este cuaderno y el código\n",
    "que debe completar se debe hacer dentro de este cuaderno. \n",
    "\n",
    "Antes de comenzar, necesita importar las librerias que necesita. Estas son\n",
    "\n",
    "* [`numpy`](http://www.numpy.org/) para operaciones entre arreglos y matrices (tensores)\n",
    "* [`matplotlib`](https://matplotlib.org/) para graficar y \n",
    "* [`scipy`](https://docs.scipy.org/doc/scipy/reference/) para computación científica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Import regular expressions to process emails\n",
    "import re\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib as mpl\n",
    "\n",
    "from IPython.display import HTML, display, clear_output\n",
    "\n",
    "try:\n",
    "    pyplot.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "except ValueError:\n",
    "    pyplot.rcParams[\"animation.html\"] = \"html5\"\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# library written for this exercise providing additional functions for assignment submission, and others\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# define the submission/grader object for this exercise\n",
    "# grader = utils.Grader()\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 K-means Clustering: Agrupamiento mediante K-means\n",
    "\n",
    "En este ejercicio, implementará el algorimo de K-means y lo usará para la compresión de imágenes. \n",
    "Primero comienza con un conjunto de datos 2D que le ayudará a ganar intuición acerca de como trabaja el \n",
    "algoritmo de K-means. Luego, usará el algoritmo de K-means para la compresión de imágenes mediante la reducción \n",
    "del número de colores que ocurren en una imagen. Solo los colores más sobresalientes de la misma.\n",
    "\n",
    "### 1.1 Implementación de K-means\n",
    "El algoritmo de K-means es un método para agrupar automáticamente datos de acuerdo a su similitud. Concretameinte,\n",
    "dado un conjunto  de datos $\\{x^{(1)} , \\cdots, x^{(m)}\\}$ (donde $x^{(i)} \\in \\mathbb{R}^n$), se requieren formar\n",
    "grupos de forma cohesiva. La intuición detrás de K-means consiste en un proceso iterativo, el cual comienza mediante\n",
    "una solución inicial aleatoria de centroidees, luego se refina esta solución inicial repetidamente obteniendo ejemplos\n",
    "donde los datos están más cerca a sus centroides, los cuales se recalculan en cada iteración.\n",
    "\n",
    "El algorimo K-means se puede entender como sigue:\n",
    "\n",
    "```python\n",
    "centroids = kMeansInitCentroids(X, K)\n",
    "for i in range(iterations):\n",
    "    # Cluster assignment step: Assign each data point to the\n",
    "    # closest centroid. idx[i] corresponds to cˆ(i), the index\n",
    "    # of the centroid assigned to example i\n",
    "    idx = findClosestCentroids(X, centroids)\n",
    "    \n",
    "    # Move centroid step: Compute means based on centroid\n",
    "    # assignments\n",
    "    centroids = computeMeans(X, idx, K)\n",
    "```\n",
    "\n",
    "El ciclo interno del algoritmo repite cada vez dos pasos: (1) Asigna una muestra de entrenamiento $x^{(i)}$\n",
    "al centroide mas cercano, y (2) recalcula la media de cada centroide usando los puntos asigados al mismo.\n",
    "El algoritmo K-means siempre converge a un conjunto final de centroides, junto con sus puntos asignados, vecinos\n",
    "de cada centroide. La solución a la que converge el algoritmo no necesariamente es la ideal. Por eso, en la práctica,\n",
    "K-means se corre solo unas pocas veces con inicializaciones aleatorias diferentes. Una forma de escoger entre \n",
    "dos soluciones diferentes, es usando una función de costo (distorción), la cual se debe minimizar. \n",
    "Usted debe implementar las dos fases del algoritmo de forma separada en la próxima sección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "#### 1.1.1 Encontrar los centroides mas cercanos\n",
    "\n",
    "En la fase de \"asignamiento de grupo\" el algoritmo de K-means asigna cada muestra de entrenamiento $x^{(i)}$\n",
    "a su centroide mas cercano, dadas las posiciones de los centroides. Específicamente, para cada muetra $i$\n",
    "asignamos\n",
    "\n",
    "\n",
    "$$c^{(i)} := j \\quad \\text{que minimiza} \\quad \\lvert\\rvert x^{(i)} - \\mu_j  \\lvert\\rvert^2, $$\n",
    "\n",
    "donde $c^{(i)}$  es el índice del centroide que está más cercano a $x^{(i)}$, y  $\\mu_j$ es la posición (valor=\n",
    "de el centroide $j^{écimo}$. Note que $c^{(i)}$ corresponde al  `idx[i]` en el código de inicio.\n",
    "\n",
    "Su tarea es completar el código en la función `findClosestCentroids`. Esta función toma la matrix de datos ´X'\n",
    "y las localizaciones de todos los centroides dentro de  `centroids` y debería arrojar un arreglo unidimensional\n",
    "`idx` que contiene el índice (un valor en el conjunto $\\{1, ..., K\\}, donde $K$ es el número total de centroides)\n",
    "del centroide mas cercano a cada muestra de entrenamiento. \n",
    "\n",
    "Usted puede implementar esto usando un ciclo por cada muestra de entrenamiento y cada centroide.\n",
    "<a id=\"findClosestCentroids\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClosestCentroids(X, centroids):\n",
    "    \"\"\"\n",
    "    Calcula el centroide asignado para cada muestra.\n",
    "    \n",
    "    Parámetros:\n",
    "    ----------\n",
    "    X : Arreglo\n",
    "        Los datos de tamaño (m,n) donde cada fila es una muestra.\n",
    "        Es decir, tenemos m muestras y n dimensiones.\n",
    "\n",
    "    centroids: arreglo\n",
    "        Los centroides de K-means de tamaño (K, n). K es el\n",
    "        número de grupos, y n es la dimensión de lo los datos.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    idx : arreglo\n",
    "        Un vector de tamaño (m, ) que contiene los centroides asignados para cada muestra\n",
    "        (fila) en los datos X.\n",
    "    \n",
    "    Instructiones\n",
    "    ------------\n",
    "    Visite cada muestra, encuentre el centroide más cercano, y\n",
    "    almacene el índice en `idx` donde le corresponde.\n",
    "    Concretameinte, idx[i] debería contener el índice del centroide\n",
    "    más cercano a la muestra i. Por esto debe ser un valor en el \n",
    "    rango 0..K-1\n",
    "\n",
    "\n",
    "    Nota\n",
    "    ----\n",
    "    Usted puede usar un ciclo for sobre las muestras para calcular esto.\n",
    "    \"\"\"\n",
    "    # asigne K\n",
    "    K = centroids.shape[0]\n",
    "\n",
    "    # debe retornar estos valores correctamente\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "\n",
    "    # ====================== Su Código Acá ======================\n",
    "\n",
    "    \n",
    "    \n",
    "    # =============================================================\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez usted halla completado el código en  `findClosestCentroids`, la siguiente celda debe\n",
    "producir la salida  `[0 2 1]` correspondiente a las asignaciones de los 3 primeras muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue los datos\n",
    "data = loadmat(os.path.join('Data', 'ex7data2.mat'))\n",
    "X = data['X']\n",
    "\n",
    "# Select los tres centroides iniciales \n",
    "K = 3   # 3 centroides\n",
    "initial_centroids = np.array([[3, 3], [6, 2], [8, 5]])\n",
    "\n",
    "# Encuentre los centroides mas cercanos a las muestras usando los centroides iniciales. \n",
    "idx = findClosestCentroids(X, initial_centroids)\n",
    "\n",
    "print('Closest centroids for the first 3 examples:')\n",
    "print(idx[:3])\n",
    "print('(the closest centroids should be 0, 2, 1 respectively)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "### 1.1.2 Calculo de los centroides (medias)\n",
    "\n",
    "Dadas las asignaciones de cada punto a un centroide, la segunda fase del algoritmo recalcula las medis para\n",
    "cada centroide. Esta centroide corresponde a la media de los puntos asignados al mismo. Específicamente,\n",
    "para cada centroide $k$ en el conjunto\n",
    "\n",
    "$$ \\mu_k := \\frac{1}{\\left| C_k\\right|} \\sum_{i \\in C_k} x^{(i)}$$\n",
    "\n",
    "Donde  $C_k$ es el conjunto de muestras asignadas al centroide $k$. Concretamente, si do muestras, por ejemplo,\n",
    " $x^{(3)}$ y $x^{(5)}$ son asignadas al centroide  $k = 2$, entondces usted debería actualizar\n",
    "  $\\mu_2 = \\frac{1}{2} \\left( x^{(3)} + x^{(5)} \\right)$.\n",
    "\n",
    "\n",
    "Usted ahora debe completar el código en la función  `computeCentroids`. Debe implementar esta función mediante\n",
    "un ciclo sobre los centroides. Tambien puede usar un ciclo sobre las muestras; pero si quiere usar una implementación\n",
    "vectorizada que no contenga este ciclo, su programa será más rápido. \n",
    "\n",
    "<a id=\"computeCentroids\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCentroids(X, idx, K):\n",
    "    \"\"\"\n",
    "    Retorna los nuevos centroides calculando las medias sobre los\n",
    "    puntos asignados a aca centroide. \n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    X : arreglo\n",
    "        Los datos donde cada fila es una muestra. Es decir, \n",
    "        es una matriz de tamaño (m, n) con m puntos y cada\n",
    "        punto con n dimensiones.\n",
    "    \n",
    "    idx : arreglo\n",
    "        Un vector (tamaño m= con las asignaciones de los centroides (es decir, cada entrada\n",
    "        en el rango  [0 ... K-1]) para cada muestra.\n",
    "        \n",
    "    \n",
    "    K : int\n",
    "        Número de grupos (clusters)\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    centroids : arreglo\n",
    "        Una matriz de tamaño (K, n) donde cada fila es la media de los puntos\n",
    "        asignados al centroide.\n",
    "    \n",
    "    Instrucciones\n",
    "    ------------\n",
    "    Visite cada centroide y calcule la media de todos los\n",
    "    puntos asignados a él. Concretamente, el vector fila de\n",
    "    centroids[i, :] debe contener la media de los datos\n",
    "    asignaos al grupo i.\n",
    "\n",
    "    Nota:\n",
    "    -----\n",
    "    Usted puede usar un ciclo for sobre los centroides para calcular esto.\n",
    "    \"\"\"\n",
    "    # variables útiles\n",
    "    m, n = X.shape\n",
    "    # necesita retornar lo siguiiente correctamente.\n",
    "    centroids = np.zeros((K, n))\n",
    "\n",
    "\n",
    "    # ====================== Su Código Acá ======================\n",
    "\n",
    "    \n",
    "    \n",
    "    # =============================================================\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez halla completado el código en  `computeCentroids`, la siguiente celda debe retornar los \n",
    "centroides luego del primer paso de K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule mas medias basado en el centroide mas cercano encontrado arriba.\n",
    "centroids = computeCentroids(X, idx, K)\n",
    "\n",
    "print('Centroides calculados luego de encontrar los centroides más cercanos: ')\n",
    "print(centroids)\n",
    "print('\\nThe centroids should be')\n",
    "print('   [ 2.428301 3.157924 ]')\n",
    "print('   [ 5.813503 2.633656 ]')\n",
    "print('   [ 7.119387 3.616684 ]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ejemplo de K-means con datos \n",
    "\n",
    "Luego  de haber completado las funciones (`findClosestCentroids` y `computeCentroids`), \n",
    "debe tener todas las piezas necesarias para correr el algoritmo K-means.  La próxima celda corre el algoritmo\n",
    "K-means on datos 2D de juguete con el fin de ayudarle a entender como trabaja K-means.  Sus funciones son llamadas\n",
    "desde la función `runKmeans` ( en este proyecto la encontrará en el módulo `utils.py`).   Le sugerimos mirar la\n",
    "función para que entienda como trabaja.  Note que el código llama las dos funciones que implementón en un ciclo.\n",
    "\n",
    "Luego de que corra el próximo paso, el código K-means producirá una animación que se desplaza mostrando el progreso\n",
    "del algoritmo en cada iteración.  Al final, su figura debe verse como la que se muestra debajo.\n",
    "![](Figures/kmeans_result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga los datos para el ejemplo\n",
    "data = loadmat(os.path.join('Data', 'ex7data2.mat'))\n",
    "\n",
    "# parametros para k-means\n",
    "K = 3\n",
    "max_iters = 10\n",
    "\n",
    "# por consistencia, aca asignamos los centroides a valores especìficos\n",
    "# sin embargo, en la práctica usted los debe generar de forma automática, \n",
    "# por ejemplo creando muestras aleatorias (como se muestra en\n",
    "# kMeansInitCentroids).\n",
    "initial_centroids = np.array([[3, 3], [6, 2], [8, 5]])\n",
    "\n",
    "\n",
    "# Corra el algoritmo K-means. El valor  'true'  al final es para graficar\n",
    "# el progreso de K-means\n",
    "centroids, idx, anim = utils.runkMeans(X, initial_centroids,\n",
    "                                       findClosestCentroids, computeCentroids, max_iters, True)\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Inicialización aleatoria\n",
    "\n",
    "Los centroides iniciales se para el ejemplo de la celda anterior fueron asignados para que usted vea\n",
    "la misma figura que se muestra en la celda. En la práctica, una buena estrategia para inicialización de\n",
    "centroides is la selección usando una función aleatoria para un conjunto de datos de entrenamiento.\n",
    "\n",
    "In esta parde el ejercicio, usted debe completar la funcón   `kMeansInitCentroids`  con el siguiente código:\n",
    "\n",
    "\n",
    "```python\n",
    "# Inicialice los centroidos con muestras aleatorias\n",
    "\n",
    "# Reordene de forma aleatoria los índices de las muestras \n",
    "randidx = np.random.permutation(X.shape[0])\n",
    "# Tome las primeras K muestras como centrroides\n",
    "centroids = X[randidx[:K], :]\n",
    "```\n",
    "\n",
    "El código de arriba inicialmente permuta los índices aleatoriamente de las muestras (usando  `permute` del módulo `numpy.random` module).  Luego selecciona las primeras $K$ muestras basado en la permutación aleatoria de los\n",
    "índices. Esto permite que las muestras sean seleccionadas aleatoriamente sin el riesgo de seleccionar una muestra\n",
    "dos veces.  \n",
    "\n",
    "\n",
    "*usted no necesita entregar esta parte del ejercicio*\n",
    "<a id=\"kMeansInitCentroids\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeansInitCentroids(X, K):\n",
    "    \"\"\"\n",
    "    Esta función inicializa los K centroides que se usan para K-means en los datos x\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    X : arreglo\n",
    "        Datos de tamaño (m x n)\n",
    "    \n",
    "    K : int\n",
    "        El número de grupos.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    centroids : arreglo\n",
    "        Centroides de los grupos. ESta es una matriz de tamaño (K x n).\n",
    "    \n",
    "    Instrucciones\n",
    "    ------------\n",
    "    Usted debe iniciar los centroides aleatoriamente de los datos X.\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # Este valor debe retornar correctamente.\n",
    "    centroids = np.zeros((K, n))\n",
    "\n",
    "    # ====================== Su Código Acá ======================\n",
    "\n",
    "\n",
    "    \n",
    "    # =============================================================\n",
    "    return centroids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Compresión de imágenes con K-means\n",
    "\n",
    "En este ejercicio, usted aplica K-means para comprimir una imagen. Usaremos la imagen de abajo (propiedad de Frank Wouters\n",
    "con  permiso para esta clase)\n",
    "\n",
    "\n",
    "![](Data/bird_small.png)\n",
    "\n",
    "En un formato directo de 24-bits de una imagen, cada pixel es representado por tres grupos de 8-bit enteros\n",
    "sin signo (unsigned integers entre 0 y 255) que especifican los colores rojo (red), verde (green) y azul (blue).\n",
    "A este formato se le conoce como RGB. Nuestra imagen contiene miles de colores, y en esta parte del ejercicio\n",
    "usted va a reducir el numero de colores a 16.\n",
    "\n",
    "Luego de esta reduccion es posible representar (en forma comprimida) la foto de forma eficiente. Específicamente,\n",
    "usted solo necesita guardar los valores RGB de los 16 colores seleccionados, y para cada pixel en la imagen usted \n",
    "solo necesita guardar el índice del color en esa localidad (donde solo 4 bits son necesarios para representar\n",
    "16 posibilidades).\n",
    "\n",
    "En este ejercicio usted usará el algoritmo de K-means para seleccionar\n",
    "16 colores que serán usados para representar una imagen comprimida. \n",
    "Concretamente, usted va a tratar cada pixel de la imagen original como una\n",
    "muestra y usará el algoritmo de K-means para encontrar los 16 colores\n",
    "que mejor agrupan los pixeles en un espacio RGB de tres dimensiones.\n",
    "Una vez usted calcule los centroides en la imagen, empleará los 16 colores\n",
    "para reemplazar los pixeles en la imagen original.\n",
    "\n",
    "#### 1.4.1 pixeles en K-means \n",
    "\n",
    "In Python, las imágenes se pueden leer como sigue\n",
    "\n",
    "```python\n",
    "# Cargue la imagen 128x128 en color (bird_small.png)\n",
    "img = mpl.image.imread(os.path.join('Data', 'bird_small.png'))\n",
    "\n",
    "# En este punto ya hemos importado la libreria matplotlib como mpl \n",
    "```\n",
    "Esto crea una matriz en tres dimensiones `A` donde los dos primeros\n",
    "índices identifican una posición de pixel y de la cual el último índice\n",
    "representa los colores rojo, verde, o azul. For ejemplo  A[50, 33, 2] \n",
    "produce una intensidad de en el pixel con fila 51 y columna 35.\n",
    "\n",
    "El código en la siguiente celda carga la imagen, y la reforma mediante\n",
    "la creación de una matriz de m x 3 de colores de pixel (donde m=16384=128 x 129), y llama la su función K-means.\n",
    "\n",
    "Luego de encontrar los K=16  colores más representativos de la imagen, \n",
    "usted puede asignar cada posición de pixel al centroide más cercano\n",
    "usando la función `findClosestCentroids`.  Esto permite que usted represente la imagen original usando las asignaciones de centroides para cada pixel.\n",
    "Note que usted ha reducido significantemente el número de bits que son necesarios para describir la imagen.  La imagen original requirió 25 bits para cada una de las 128 x 128 localizaciones de pixeles, resultando en un\n",
    "tamaño de 128 x 128 x 24 = 393,216 bits. La nueva representación requiere\n",
    "un trabajo adicional de memoria en forma de un diccionario de 16 colores,\n",
    "cada uno de los cuales requiere 24 bits, pero la imagen solo requiere 4 bits por ubicación de pixel.  El numero final de bits usado es entonces 16 x 24 + 128 x 128 x 4 = 65,920 bits, que corresponden a la imagen orignal comprimida por un factor de 6.\n",
    "\n",
    "Finalmente, usted puede ver los efectos de la compresión mediante la\n",
    "reconstrucción de la imagen basada solo en las asignaciones de centroides. Específicamente, usted puede reemplazar cada ubicación de pixel con \n",
    "la media asignada. La figura siguiente muestra la reconstrucción obtenida.\n",
    "\n",
    "![](Figures/bird_compression.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aún cuando la imagen resultante retiene la mayoría de las características de la imagen original, se alcanzan a ver algunos artifactos de la compresión.\n",
    "\n",
    "Correa la siguiente celta para calcular los centroides y la localización\n",
    "de cada pixel en la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Experimente con estos parámetros ================\n",
    "# Por favor intente varios parámetros\n",
    "K = 16\n",
    "max_iters = 10\n",
    "\n",
    "# Load an image of a bird\n",
    "# cambie el nombre del archivo y directorio para experimentar con sus propias imágenes\n",
    "A = mpl.image.imread(os.path.join('Data', 'bird_small.png'))\n",
    "# ==========================================================\n",
    "\n",
    "# Divida por 255 para que todos los valres queden entre 0 y 1.\n",
    "A /= 255\n",
    "\n",
    "# Reforme la imagen en una matriz Nx3 donde N=número de pixeles\n",
    "# Cada fila debe contener los valores de los pixeles \"Red, Green, Blue\"\n",
    "# La siguiente linea debe contener nuestra matriz X que usamos para K-means.\n",
    "X = A.reshape(-1, 3)\n",
    "\n",
    "# Cuando se usa K-means es importante inicializar los centroides aleatoriamente\n",
    "# Usted debe completar el código KMeansInitCentroids antes de continuar.\n",
    "initial_centroids = kMeansInitCentroids(X, K)\n",
    "\n",
    "# Corra K-means\n",
    "centroids, idx = utils.runkMeans(X, initial_centroids,\n",
    "                                 findClosestCentroids,\n",
    "                                 computeCentroids,\n",
    "                                 max_iters)\n",
    "\n",
    "# Ahora podemos recobrar la imagen desde los índices (idx) mapeando cada pixel\n",
    "# (especificado por su índice idx) para el valor del centroide\n",
    "# Reforme la imagen en las dimensiones adecuadas.\n",
    "# We can now recover the image from the indices (idx) by mapping each pixel\n",
    "# (specified by its index in idx) to the centroid value\n",
    "X_recovered = centroids[idx, :].reshape(A.shape)\n",
    "\n",
    "# Grafique la imagen original y escale (para recobrar la escala) por 255\n",
    "fig, ax = pyplot.subplots(1, 2, figsize=(8, 4))\n",
    "ax[0].imshow(A*255)\n",
    "ax[0].set_title('Original')\n",
    "ax[0].grid(False)\n",
    "\n",
    "# Grafique la imagen comprimida y escale (para recobrar la escala) por 255\n",
    "ax[1].imshow(X_recovered*255)\n",
    "ax[1].set_title('Compressed, with %d colors' % K)\n",
    "ax[1].grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Usted no necesita presentar esta parte del ejercicio*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Ejercicio opcional (no se califica) : Use su propia imagen\n",
    "\n",
    "En este ejercicio, modifique su codigo para correrlo con una de sus imágenes. Observe que si su imagen es muy grande, entonces K-means\n",
    "puede tomar mucho tiempo para correr. Recomendamos que cambie el\n",
    "tamaño de su imagen de forma que sea apropiado para correr su código.\n",
    "Tambien puede variar $K$ para ver los efectos de la compresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Análisis de Componente Principal (PCA)\n",
    "\n",
    "En este ejercicio usted usará PCA para reducir la dimensión de sus datos.\n",
    "Primero vamos a experimentar con un ejemplo en 2D para desarrollar intuición de como trabaja el PCA, luego usaremos un conjunto mas grande de datos consistente en 5000 caras.\n",
    "\n",
    "### 2.1 Datos de Ejemplo\n",
    "\n",
    "Para ayudar a entender como trabaja el PCA, comenzamos con un conjunto de datos 2D que tiene una variación grande en una dirección y otra mas pequeña en otra dirección. La celda siguiente grafica los datos de entrenamiento.\n",
    "\n",
    "En esta parte del ejercicio se visualiza lo que pasa cuando se usa PCA para reducir datos de 2D a 1D. In la práctica usted podría querer rebajar de 256 dimensiones a 50 dimensiones, por ejemplo; sin embargo usando dimensiones más pequeñas nos permiten visualizar mejor el algoritmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue los datos en la variabla X\n",
    "data = loadmat(os.path.join('Data', 'ex7data1.mat'))\n",
    "X = data['X']\n",
    "\n",
    "#  Visualice los datos\n",
    "pyplot.plot(X[:, 0], X[:, 1], 'bo', ms=10, mec='k', mew=1)\n",
    "pyplot.axis([0.5, 6.5, 2, 8])\n",
    "pyplot.gca().set_aspect('equal')\n",
    "pyplot.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "### 2.2 Implementación de PCA\n",
    "\n",
    "In esta parte usted implementará PCA. PCA consiste de 2 etapas.\n",
    "\n",
    "1. Calcular la matriz de covarianza de los datos.\n",
    "2. Usar SVD (en Python usamos la función de NumPy `np.linalg.svd`) para calcular los autvectores $U_1$, $U_2$, $\\dots$, $U_n$. Estos corresponden a las componentes principales de variación en los datos.\n",
    "\n",
    "Inicialmente usted debe calcular la matriz de covarianza de los \n",
    "datos, la cual está data por\n",
    "\n",
    "$$ \\Sigma = \\frac{1}{m} X^T X$$\n",
    "\n",
    "donde $X$ corresponde a la matriz de datos (cada dato es una fila), y $m$ es el número de datos.  Note que $\\Sigma$ es una matriz de tamaño $n \\times n$\n",
    "y no el operador suma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de calcular la matriz de covarianza usted puede correr la descomposición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  SVD para calcular las componentes principales. En Python y  `numpy` (o `scipy`),\n",
    "usted puede correr SVD con el siguiente comando: `U, S, V = np.linalg.svd(Sigma)`, donde `U` contiene las componentes principales y `S` contiene la matriz diagonal. Note que la librería  `scipy` tiene funciones similares para calcular la descomposición SVD `scipy.linalg.svd`. Las funciones en las dos librerías usan el mismo código basado en la librería en C (LAPACK) para la implementación SVD, sin embargo la versión `scipy` \n",
    "proporciona más opciones y argumentos para controlar el cálculo de SVD.\n",
    "En este ejercicio nos mantenemos en `numpy` para la implementación de SVD.\n",
    "\n",
    "Complete el código en la siguiente celda para implementar PCA.\n",
    "\n",
    "<a id=\"pca\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advertencia! : Lo que en este proyecto se llama U es realmente V como lo discutimos en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X):\n",
    "    \"\"\"\n",
    "    Corra PCA\n",
    "    \n",
    "    Parametros\n",
    "    ----------\n",
    "    X : arreglo \n",
    "        Los datos para usar con PCA. Las dimensiones son (m x n)\n",
    "        donde m es el número de muestras (observaciones) y n es\n",
    "        el número de atributos.\n",
    "        \n",
    "    \n",
    "    Returna\n",
    "    -------\n",
    "    U : arreglo\n",
    "        Los autovectores. Representan las componentes principales\n",
    "        de X, U con dimensiones (n x n) donde cada columna es una\n",
    "        componente principal.\n",
    "    \n",
    "    S : arreglo\n",
    "        Un vector de tamaño n, con los valores singulares para cada\n",
    "        componente. Note que esta es la matriz diagonal mencionada\n",
    "        en clase. \n",
    "    \n",
    "    Instrucciones\n",
    "    ------------\n",
    "    Debe calcular primero la matriz de covarianza. Luego debe\n",
    "    usar la función \"svd\" para calcular los autovectores y \n",
    "    autovalores de la matriz de convarianza.\n",
    "\n",
    "    Notas\n",
    "    -----\n",
    "    Recuerde dividir por m cuando calcule la matriz de covarianza,\n",
    "    donde m es el número de muestras.\n",
    "    \"\"\"\n",
    "    # valores útiles\n",
    "    m, n = X.shape\n",
    "\n",
    "    # necesita retornar las siguientes variables\n",
    "    U = np.zeros(n)\n",
    "    S = np.zeros(n)\n",
    "\n",
    "    # ====================== Su Código Acá ======================\n",
    "\n",
    "    \n",
    "    \n",
    "    # ============================================================\n",
    "    return U, S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de calcular PCA es importante normalizar los datos, restando el valor medio de cada atributo de los datos y escalando cada dimension de forma que los datos esten en el mismo rango.\n",
    "\n",
    "En la siguiente celda la normalización se ejecuta mediante el uso de\n",
    "la función `utils.featureNormalize` .\n",
    "Luego de normalizar los datos puede correr PCA para calcular las \n",
    "componentes principales. Su tarea es completar el código `pca`\n",
    "para calcular las componentes principlaes de los datos.\n",
    "\n",
    "Una vez halla completado la función `pca`, la celda siguiente corre el\n",
    "análisis PCA en el los datos y grafica las componentes principales encontradas en la figura de abajo.\n",
    "\n",
    "![](Figures/pca_components.png)\n",
    "\n",
    "La siguiente celda tambien muestra la componente principal (autovector)\n",
    "encontrada y debe observar la salida `[-0.707 -0.707]`. (Es posible que\n",
    "`numpy`  pueda arrojar, en vez,  el negativo de este vector, since tanto \n",
    "$U_1$ como $-U_1$  son igualmente válidas para la componente principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Antes de correr el PCA es importante normalizar los datos\n",
    "X_norm, mu, sigma = utils.featureNormalize(X)\n",
    "\n",
    "#  Corra PCA\n",
    "U, S = pca(X_norm)\n",
    "\n",
    "#  Grafique las direcciones de máxima variación de los datos.\n",
    "#  Grafique los autovectores centrados en la media de los datos.\n",
    "#  Estas líneas muestran las direcciones de máxima variación de los datos.\n",
    "\n",
    "fig, ax = pyplot.subplots()\n",
    "ax.plot(X[:, 0], X[:, 1], 'bo', ms=10, mec='k', mew=0.25)\n",
    "\n",
    "for i in range(2):\n",
    "    ax.arrow(mu[0], mu[1], 1.5 * S[i]*U[0, i], 1.5 * S[i]*U[1, i],\n",
    "             head_width=0.25, head_length=0.2, fc='k', ec='k', lw=2, zorder=1000)\n",
    "\n",
    "ax.axis([0.5, 6.5, 2, 8])\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(False)\n",
    "\n",
    "print('Top eigenvector: U[:, 0] = [{:.6f} {:.6f}]'.format(U[0, 0], U[1, 0]))\n",
    "print(' (you should expect to see [-0.707107 -0.707107])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Reducción de dimensionalidad mediante PCA\n",
    "\n",
    "Luego de calcular las componentes principales, las puede usar para\n",
    "reducir la dimension de atributos de los datos mediante la proyección\n",
    "de las muestras a un espacio de  dimensión más pequeña , $x^{(i)} \\rightarrow z^{(i)}$ (por ejemplo, proyectando los datos de 2D a 1D).\n",
    "In esta parte del ejercicio usted usará los autovectores retornados\n",
    "por PCA y proyectará los datos a un espacio de una dimensión. En la práctica, si usted usa un algoritmo de aprendizaje tal como regresión lineal o redes neuronales, puede usar ahora los datos proyectados, en vez de los originales.  Mediante el uso de los datos proyectados, usted puede entrenar su modelo mas rápido puesto que tiene un número más pequeño de dimensiones.\n",
    "<a id=\"section4\"></a>\n",
    "\n",
    "#### 2.3.1 Proyección de los datos originales en las componentes principales.\n",
    "\n",
    "Ahora debe completar el código en la función `projectData`.\n",
    "Específicamente, dado un conjunto `X`, las componentes principales\n",
    "`U`, y el número deseado de dimensiones `K`, debes proyectar\n",
    "aca muestra en `X` en las  `K` components mayores de `U`.\n",
    "Note que las `K` components mayores de `U` estan daas por \n",
    "\n",
    "`Ureduce = U[:, :K]`.\n",
    "<a id=\"projectData\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projectData(X, U, K):\n",
    "    \"\"\"\n",
    "    Calcula los datos reducidos proyectando los datos originales\n",
    "    a lo largo de los K autovectores más importantes. \n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    X : arreglo\n",
    "        Los datos de entrada tienen dimensiones (m x n). Se asumen\n",
    "        normalizados.\n",
    "    \n",
    "    U : arreglo\n",
    "        Los autovectores se calculan usando PCA. Esto produce\n",
    "        una matriz de dimensiones (n x n). Cada columna de la matriz\n",
    "        representa un autovector (o componente principal).\n",
    "    \n",
    "    K : int\n",
    "        Número de dimensiones del espacio proyectado. Debe ser menor que n.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Z : arreglo\n",
    "        La proyeccion de los datos de acuerdo a los K autovectores más significativos.\n",
    "        Esta debe ser una matriz de orden (m x k).\n",
    "    \n",
    "    Instrucciones\n",
    "    ------------\n",
    "    Calcule la proyección de los datos sobre los K\n",
    "    autovectores mas importantes (con los mayores valores singulares)\n",
    "    de la matriz U ( las primeras K columnas, poroducen W en las notas de clase).\n",
    "    Para la muestra i, es decir X[i,:[, la proyección en el autovector  k\n",
    "    esta dada por:\n",
    "    \n",
    "    \n",
    "        x = X[i, :]\n",
    "        projection_k = np.dot(x,  U[:, k])\n",
    "\n",
    "    \"\"\"\n",
    "    # debe retornar la siguiente variable correctamente\n",
    "    Z = np.zeros((X.shape[0], K))\n",
    "\n",
    "    # ====================== Su Còdigo Acá ======================\n",
    "\n",
    "\n",
    "    \n",
    "    # =============================================================\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez halla completado su código en  `projectData`, verifique que la pròxima celda proyecte la primera muestra de la primera dimensión y debería observar un valor de 1.481\n",
    "(o posiblemente -1.481, si usa $-U_1$ en vez de $U_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Proyecte los datos a la primera dimensión.\n",
    "K = 1\n",
    "Z = projectData(X_norm, U, K)\n",
    "print('Projection of the first example: {:.6f}'.format(Z[0, 0]))\n",
    "print('(this value should be about    : 1.481274)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "#### 2.3.2 Reconstrucción aproximada de los datos\n",
    "\n",
    "Luego de haber proyectado sus datos en un espacio de baja dimensión, debe aproximar una reconstrucción de los datos  proyectándolos al espacio original \n",
    "de altas dimensiones. Su tarea es completar la función `recoverData` que proyecta cada muestra en `Z` al espacio original recobrado en  `Xrec`.\n",
    "<a id=\"recoverData\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoverData(Z, U, K):\n",
    "    \"\"\"\n",
    "    Recobra una aproximación a los datos originales usando\n",
    "    los datos proyectados. \n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    Z : arreglo\n",
    "        Los datos reducidos mediante PCA. Esta es una matriz\n",
    "        de dimensiones (m x K ).\n",
    "    \n",
    "    U : arreglo\n",
    "        Los autovectores (componentes principales) calculados mediante PCA.\n",
    "        Esta es una matriz de tamaño (n x n) donde las columnas representan\n",
    "        autovectores de la matriz de covarianza. \n",
    "    \n",
    "    K : int\n",
    "        El número de componentes principales que se quiera retener.\n",
    "        (debe ser menor que n)\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    X_rec : arreglo\n",
    "        Los datos recobrados luego de transformar los datos proyectados\n",
    "        al espacio original. Esta matriz es de tamaño (m x n), donde\n",
    "        m es el número de muestras y n es la dimensión del espacio\n",
    "        (nùmero de atributos de los datos originales)\n",
    "    \n",
    "    Instrucciones\n",
    "    ------------\n",
    "    Calcule la aproximaciòn de los datos mediante la proyección \n",
    "    inversa al espacio orignal usando los K autovectores principales \n",
    "    de U (los primeros).  Para la muestra i, es decir Z[i, :], los\n",
    "    datos aproximados (recobrados) está dado por\n",
    "\n",
    "        v = Z[i, :]\n",
    "        recovered_j = np.dot(v, U[j, :K])\n",
    "\n",
    "\n",
    "    Note que  U[j, :K] es un vector de tamaño K.\n",
    "    \"\"\"\n",
    "    # Debe retornar la siguiente variable correctamente\n",
    "    X_rec = np.zeros((Z.shape[0], U.shape[0]))\n",
    "\n",
    "    # ====================== Su Código Acá ======================\n",
    "\n",
    "    \n",
    "\n",
    "    # =============================================================\n",
    "    return X_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez halla compledado su código en  `recoverData`, la siguiente celda recorba la aproximación de la primera muestra , la cual debe tener un valor cercano a  `[-1.047 -1.047]`.  Su cógigo debe graficar\n",
    "los datos en este espacio reducido.   Esto te muestra como deben lucir los datos luego del uso de los correspondientes autovalores que los construyen. Un ejemplo de como la proyección PCA debe lucir sse \n",
    "muestra en la siguiente figura:\n",
    "\n",
    "\n",
    "\n",
    "![](Figures/pca_reconstruction.png)\n",
    "\n",
    "\n",
    "En la figura de arriba los puntos originales se indican con círculos azules, mientras que los datos proyectados se indican con círculos rojos. La proyección efectivamente retiene la información\n",
    "en la dirección $U_1$. Las lineas punteadas muestran las distancias desde los puntos en el espacio original hasta el espacio proyectado. Estos lineas punteadas representan el error debdido\n",
    "a la proyección PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rec  = recoverData(Z, U, K)\n",
    "print('Approximation of the first example: [{:.6f} {:.6f}]'.format(X_rec[0, 0], X_rec[0, 1]))\n",
    "print('       (this value should be about  [-1.047419 -1.047419])')\n",
    "\n",
    "#  Grafique los datos normalizados (retornados de featureNormalize)\n",
    "\n",
    "fig, ax = pyplot.subplots(figsize=(5, 5))\n",
    "ax.plot(X_norm[:, 0], X_norm[:, 1], 'bo', ms=8, mec='b', mew=0.5)\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(False)\n",
    "pyplot.axis([-3, 2.75, -3, 2.75])\n",
    "\n",
    "# Dibuje las líneas que conectan los puntos proyectados a los puntos originaes.\n",
    "ax.plot(X_rec[:, 0], X_rec[:, 1], 'ro', mec='r', mew=2, mfc='none')\n",
    "for xnorm, xrec in zip(X_norm, X_rec):\n",
    "    ax.plot([xnorm[0], xrec[0]], [xnorm[1], xrec[1]], '--k', lw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Datos de imagenes de caras\n",
    "\n",
    "En esta parte del ejercicio, usted debe correr PCA en las imagenes de caras para ver como se usa el algoritmo en la práctica con el fin de reducir dimensionalidad.  Los datos `ex7faces.mat` contienen las muestras que se almacenan en la matriz `X` con las imágenes de las caras, cada imagen de tamaño $32 \\times 32$ en escala de grises.  Los datos se basan en [cropped version](http://conradsanderson.id.au/lfwcrop/) del conjunto [labeled faces in the wild](http://vis-www.cs.umass.edu/lfw/). Cada fila de `X` corresponde a una cara de la imagen de caras (un vector de longitud 1024). \n",
    "\n",
    "\n",
    "La pròxima celda carga y visualiza las primeras 100 caras. Deben lucir similares a esta figura:\n",
    "![Faces](Figures/faces.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Cargue los datos con las caras\n",
    "data = loadmat(os.path.join('Data', 'ex7faces.mat'))\n",
    "X = data['X']\n",
    "\n",
    "#  Muestre las primeras 100 caras.\n",
    "utils.displayData(X[:100, :], figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 PCA en Caras\n",
    "\n",
    "Para correr el PCA en los datos de caras, inicialmente noramlizamos los datos, retando la media de cada atributo en la matriz `X`. Luego de correr el algoritmo\n",
    "de PCA usted debe obtener las componentes principales. Note que cada componente princial en  `U` (cada columna) es un vector de longitud\n",
    "\n",
    "To run PCA on the face dataset, we first normalize the dataset by subtracting the mean of each feature from the data matrix `X`.  After running PCA, you will obtain the principal components of the dataset. Notice that each principal component in `U` (each column) is a vector of length $n$ (where for the face dataset, $n = 1024$). It turns out that we can visualize these principal components by reshaping each of them into a $32 \\times 32$ matrix that corresponds to the pixels in the original dataset. \n",
    "\n",
    "The following cell will first normalize the dataset for you and then run your PCA code. Then, the first 36 principal components (conveniently called eigenfaces) that describe the largest variations are displayed. If you want, you can also change the code to display more principal components to see how they capture more and more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  normalice X restando la media de cada atributo\n",
    "X_norm, mu, sigma = utils.featureNormalize(X)\n",
    "\n",
    "#  Corra PCA\n",
    "U, S = pca(X_norm)\n",
    "\n",
    "#  Visualice las primeras 36 autovalores encontrados\n",
    "utils.displayData(U[:, :36].T, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Reducción de dimensionalidad\n",
    "\n",
    "Ahora que ya se tienen las componentes principales de los datos, se pueden usar para reducir la dimension de los mismos. Esto permite\n",
    "que su algoritmo aprenda con un conjunto con datos de menor tamaño (por ejemplo 100 dimensiones) en vez de la dimension original de 1024.\n",
    "Esto puede ayudar a incrementar la velocidad en el algoritmo de aprendizaje.\n",
    "\n",
    "La pròxima celda proyecta los datos de las caras a las primeras 100 componentes principales. Concretamente, cada imagen de cara se describe\n",
    "por el vector $z^{(i)} \\in \\mathbb{R}^{100}$. Para entender que se pierde en la reducciòn de dimensionalidad, puede recobrar los datos usando\n",
    "solo los datos proyectados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Proyecte las imagenes en el autoespacio usando los k autovectores principales \n",
    "K = 100\n",
    "Z = projectData(X_norm, U, K)\n",
    "\n",
    "print('The projected data Z has a shape of: ', Z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La próxima celda aproxima los datos recobrados usando los datos proyectados. Se muestran \n",
    "los datos originales y los recobrados de forma similar a la mostrada acá.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"Figures/faces_original.png\" width=\"300\"></td>\n",
    "        <td><img src=\"Figures/faces_reconstructed.png\" width=\"300\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "De la reconstruccion se observa que en general la estructura y apariencia de las caras se conserva, salvo pequeños detalles. Esta es una reducción\n",
    "importante (mas de 10x) en el tamaño de los datos que puede ayudar a mejorar la velocidad de aprendizaje significativamente. Por ejemplo, si usted\n",
    "esta entrenando una red neuronal para reconocimiento de caras, usted puede usar los datos reducidos a 100 dimensiones en vez de las dimensiones\n",
    "representadas por los pixeles originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Poryecte las imagenes al autoespacio usando los primeros K autovectores y\n",
    "#  visualice solo las primeras K dimensiones\n",
    "#  compare con la entrada original, que se muestra\n",
    "K = 100\n",
    "X_rec  = recoverData(Z, U, K)\n",
    "\n",
    "# muestre los datos normalizados\n",
    "utils.displayData(X_norm[:100, :], figsize=(6, 6))\n",
    "pyplot.gcf().suptitle('Original faces')\n",
    "\n",
    "# Display reconstructed data from only k eigenfaces\n",
    "# muestre los datos reconstruidos solo ocn k autovectores\n",
    "utils.displayData(X_rec[:100, :], figsize=(6, 6))\n",
    "pyplot.gcf().suptitle('Recovered faces')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Ejercicio opcional para visualizacion con PCA. No se califica.\n",
    "En el ejercicio anterior de K-means se usó k-means en un espacio 3-dimensional RGB. Redujimos cada pixel de la imagen RGB para ser representado\n",
    "paor 16 grupos (clusters). En la próxima celda, mostramos un código para visualizar las asignaciones de pixeles finales en el espacio 3D.\n",
    "Cada punto es coloreado de acuerdo al grupo en el que fue clasificado. Usted puede arrastar el ratón en la figura para rotar e inspeccionar los datos en\n",
    "3 dimensiones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto permite interactividad para rotar la gráfic 3D\n",
    "# La repetición de la linea de código se hace a propósito\n",
    "# ver: https://stackoverflow.com/questions/43545050/using-matplotlib-notebook-after-matplotlib-inline-in-jupyter-notebook-doesnt\n",
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "A = mpl.image.imread(os.path.join('Data', 'bird_small.png'))\n",
    "A /= 255\n",
    "X = A.reshape(-1, 3)\n",
    "\n",
    "# ejecute el agrupamiento K'means acá.\n",
    "K = 16\n",
    "max_iters = 10\n",
    "initial_centroids = kMeansInitCentroids(X, K)\n",
    "centroids, idx = utils.runkMeans(X, initial_centroids,\n",
    "                                 findClosestCentroids,\n",
    "                                 computeCentroids, max_iters)\n",
    "\n",
    "#  Escoja 1000 muestras aleatorias, debido a que trabajar con todos\n",
    "#  los datos es costoso.  Si tiene un computador rápido puede incrementar\n",
    "#  esto.\n",
    "sel = np.random.choice(X.shape[0], size=1000)\n",
    "\n",
    "fig = pyplot.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X[sel, 0], X[sel, 1], X[sel, 2], cmap='rainbow', c=idx[sel], s=8**2)\n",
    "ax.set_title('Pixel dataset plotted in 3D.\\nColor shows centroid memberships')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La visualización de datos en 3 dimensiones o más es complicada. Por eso, es mejor visualizar datos en 2D, aún si se pierde una dimensión.\n",
    "En la práctica, PCA se usa para reducir la dimensionalidad y permitir una mejor visualización.\n",
    "\n",
    "La próxima celda aplica la implementación de PCA en un conjunto de 3 dimensiones para reducirlo a 2 dimensiones y visualizar el resultado en una\n",
    "gráfica tipo ¨scatter plot¨ 2D. La proyección PCA puede entenderse como una rotación que selecciona la vista donde los datos están mayormente\n",
    "regados. Esta sería la \"mejor\" visualización. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reste la media para normalizar\n",
    "X_norm, mu, sigma = utils.featureNormalize(X)\n",
    "\n",
    "# use PCA para proyectar a 2D\n",
    "U, S = pca(X_norm)\n",
    "Z = projectData(X_norm, U, 2)\n",
    "\n",
    "# Reseté matplotlib para que sea no interactivo\n",
    "%matplotlib inline\n",
    "\n",
    "fig = pyplot.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(Z[sel, 0], Z[sel, 1], cmap='rainbow', c=idx[sel], s=64)\n",
    "ax.set_title('Pixel dataset plotted in 2D, using PCA for dimensionality reduction')\n",
    "ax.grid(False)\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
