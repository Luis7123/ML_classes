{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal regularizada:  Bias vs Variance (Sesgo vs Varianza)\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En este ejercicio usted va a implementar la regresión lineal con el propósito de estudiar\n",
    "models con propiedades distintas de bias-variance.  Antes de comenzar el ejercicio de programación, le recomendamos ver los videos de clase- \n",
    "\n",
    "Toda la informacion que se requiere para resolver esta tarea está en este cuaderno, y todo el código está contenido\n",
    "acá. \n",
    "\n",
    "Antes de comenzar con los ejercicios, necesitamos importar las librerías requeridas. \n",
    "Vamos a usar [`numpy`](http://www.numpy.org/) para todos los arreglos y operaciones de matrices\n",
    "[`matplotlib`](https://matplotlib.org/) para graficar y  [`scipy`](https://docs.scipy.org/doc/scipy/reference/) \n",
    "para las operaciones cientìficas. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se usa para manipular caminos\n",
    "import os\n",
    "\n",
    "# vectores y matrices y mas\n",
    "import numpy as np\n",
    "\n",
    "# para graficar\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# optimizacion con scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# para cargar el archivo en MATLAB\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# es parte del paquete para ayudar con funciones auxiliares\n",
    "import utils\n",
    "\n",
    "\n",
    "# graficas dentro de este cuaderno\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "## Regresión lineal regularizada\n",
    "\n",
    "En la primera mitad del ejercicio usted implementará un regresión lineal regularizada, la cual predice la cantidad\n",
    "de agua que fluye de una represa, mediante el cambio del nivel de agua en el reservorio. En la próxima mitad usted\n",
    "examinará algunos diagnósticos y algoritmos de depuración para analizar el sesgo versus la varianza.\n",
    "\n",
    "\n",
    "### 1.1 Visualización de datos\n",
    "\n",
    "Comenzamos con la visualización de los datos que contienen los registros históricos del cambio de nivel de agua,\n",
    "$x$, y la cantidad de agua que fluye fuera de la represa, $y$. Estos datos se dividen en 3 partes.\n",
    "\n",
    "- Un conjunto de **entrenamiento** sobre el cual se aprende el modelo sobre: `X`, `y`\n",
    "- Un conjunto de **validación cruzada** para determinar el paràmetro de regularización: `Xval`, `yval`\n",
    "- Un conjunto de **prueba** para evaluar el desempeño. Estas son muestras \"no vistas\" durante el entrenamiento: `Xtest`, `ytest`\n",
    "\n",
    "Corra la próxima celda para graficar los datos de entrenamiento. En las celdas siguientes usted debe implementar una regresión lineal para ajustar los datos a una línea recta y graficar las curvas. Luego usted debe implementar una regresión polinómica para encontrar un mejor ajuste a los datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue los datos de ex5data.mat. Las variables estàn almacenadas en un diccionario\n",
    "data = loadmat(os.path.join('Data', 'ex5data1.mat'))\n",
    "\n",
    "# Extraiga los datos de entrenamiento, validación y prueba del diccionario\n",
    "# luego convierta los yś de una matriz 2D (en formato MATLAB) a un vector en NumPY\n",
    "X, y = data['X'], data['y'][:, 0]\n",
    "Xtest, ytest = data['Xtest'], data['ytest'][:, 0]\n",
    "Xval, yval = data['Xval'], data['yval'][:, 0]\n",
    "\n",
    "# m = número de muestras\n",
    "m = y.size\n",
    "\n",
    "# grafique los datos de entrenamiento\n",
    "pyplot.plot(X, y, 'ro', ms=10, mec='k', mew=1)\n",
    "pyplot.xlabel('Change in water level (x)')\n",
    "pyplot.ylabel('Water flowing out of the dam (y)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Función de costo de regresión lineal regularizada\n",
    "\n",
    "Recuerde que la ecuaciòn de costo  de regresión lineal regularizada està dada por:\n",
    "\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\left( \\sum_{i=1}^m \\left( h_\\theta\\left( x^{(i)} \\right) - y^{(i)} \\right)^2 \\right) + \\frac{\\lambda}{2m} \\left( \\sum_{j=1}^n \\theta_j^2 \\right)$$\n",
    "\n",
    "donde $\\lambda$ es el parámetro de regularización el cual controla el grado de regularización (este previene el\n",
    "sobreajuste). El término de regularización agrega una función penalti a la función de costo $J$. A medida que las\n",
    "magnitudes de los parámetors $\\theta_j$ crecen la función de penalti incrementa. Note que no debemos regularizar\n",
    "el parámetro $\\theta_0$. \n",
    "\n",
    "Por favor complete el código de la función `linearRegCostFunction` en la próxima celda. Si es posible trate de\n",
    "vectorizar su codigo para evitar ciclos. \n",
    "\n",
    "<a id=\"linearRegCostFunction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearRegCostFunction(X, y, theta, lambda_=0.0):\n",
    "    \"\"\"\n",
    "    Calcule la función de costo y su grardiente para la regresión\n",
    "    lineal regularizada con variables múltiples. La función de\n",
    "    costo usa el parámetro theta para ajustar los puntos X y y\n",
    "    al modelo lineal. \n",
    "    \n",
    "    \n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    X : arreglo\n",
    "        Los datos. Matriz con tamaño (m x n + 1) donde m es \n",
    "        el número total de muestras y n es el número de atributos\n",
    "        (features) antes de sumar el sesgo. \n",
    "        \n",
    "       \n",
    "    y : arreglo\n",
    "        Las etiquetas para cada punto de los datos. Es un\n",
    "        vector de tamaño  (m, ).\n",
    "    \n",
    "    theta : arreglo\n",
    "        Estos son los parámetros a aprender. \n",
    "        Es un vector de tamaño (n+1,).\n",
    "    \n",
    "    lambda_ : float. Opcional\n",
    "        Parámetro de regularización\n",
    "    \n",
    "    Returna\n",
    "    -------\n",
    "    J : float\n",
    "        Función de costo\n",
    "    \n",
    "    grad : arreglo\n",
    "        El valor del gradiente de la función de costo\n",
    "        con respecto a theta.\n",
    "        Un vector de tamaño (n+1, ).\n",
    "    \n",
    "    Instrucciones:\n",
    "    ------------\n",
    "    Calcule la función de costo y su gradiente para la regresión\n",
    "    lineal regularizada y particularmente la sección de theta.\n",
    "    Llame J a la función de costo y grad a su gradiente. \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # Inicialice algunos valores útiles\n",
    "    m = y.size # número de muestras de entrenamiento\n",
    "\n",
    "    # debe retornar esto correctamente.\n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    # ====================== SU CÓDIGO ACÁ ======================\n",
    "\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez termine prueba la siguiente celda con theta inicializado a  `[1, 1]`. \n",
    "Debería obtener una salida de 303.993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array([1, 1])\n",
    "J, _ = linearRegCostFunction(np.concatenate([np.ones((m, 1)), X], axis=1), y, theta, 1)\n",
    "\n",
    "print('Cost at theta = [1, 1]:\\t   %f ' % J)\n",
    "print('This value should be about 303.993192)\\n' % J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "### 1.3 Gradiente de regresión lineal regularizada\n",
    "\n",
    "La derivada parcial de la función de costo regularizada para la regresión lineal está dado porÑ\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "& \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left(x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} & \\qquad \\text{for } j = 0 \\\\\n",
    "& \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\left( \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} \\right) + \\frac{\\lambda}{m} \\theta_j & \\qquad \\text{for } j \\ge 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "En la función  [`linearRegCostFunction`](#linearRegCostFunction) arriba adicione codigo para calcular el gradient, y\n",
    "retorne  `grad`. <font color='red'><b>Recuerde que debe volver a ejecutar la celda junto con esta función.</b></font>\n",
    "\n",
    "Una vez termine use la próxima celda para obtener el gradiente usando un theta inicializado en  `[1, 1]`. \n",
    "Debería obtener un valor de  `[-15.30, 598.250]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array([1, 1])\n",
    "J, grad = linearRegCostFunction(np.concatenate([np.ones((m, 1)), X], axis=1), y, theta, 1)\n",
    "\n",
    "print('Gradient at theta = [1, 1]:  [{:.6f}, {:.6f}] '.format(*grad))\n",
    "print(' (this value should be about [-15.303016, 598.250744])\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de regresión lineal\n",
    "\n",
    "Una vez la función de costo y su gradiente están correctamente implementada, debe correr la siguiente celda\n",
    "bajo el código en  `trainLinearReg` (la encuentra en el módulo `utils.py`) con el fin de calcular los valores\n",
    "óptimos de $\\theta$.  El entrenamiento usa un módulo de optimización de  `scipy`.\n",
    "\n",
    "En esta parte asumimos el parámetro de regularización $\\lambda$ igual 0. Dado que la implementación de la regresión\n",
    "se hace sobre un conjunto 2-dimensional $\\theta$, la regularización no es muy util para un $\\theta$ de tan baja dimensiòn.\n",
    "Màs tarde usted va a implementar una regresión polinomial con regularización. \n",
    "\n",
    "Finalmente, el código en la siguiente celda debe graficar la línea que mejor se ajusta, la cual se debe ver\n",
    "como la línea abajo.\n",
    "\n",
    "\n",
    "![](Figures/linear_fit.png)\n",
    "\n",
    "La linea que mejor se ajusta nos dice que el modelo no es bueno dado que los datos no tienen un patrón lineal.\n",
    "Esta visualización es de gran ayuda para depurar el algoritmo de aprendizaje. No siempre es fácil visualizar\n",
    "los datos y los modelos. En la próxima sección implementaremos una función que genera curvas de aprendizaje, las\n",
    "cuales ayudan a depurar el algoritmo de apendizaje, aún si  los datos no son de fácil visualización.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregar columna de unos para el intercepto\n",
    "X_aug = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "theta = utils.trainLinearReg(linearRegCostFunction, X_aug, y, lambda_=0)\n",
    "\n",
    "#  Grafique el ajuste sobre los datos\n",
    "pyplot.plot(X, y, 'ro', ms=10, mec='k', mew=1.5)\n",
    "pyplot.xlabel('Change in water level (x)')\n",
    "pyplot.ylabel('Water flowing out of the dam (y)')\n",
    "pyplot.plot(X, np.dot(X_aug, theta), '--', lw=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "## 2 Bias vs variance\n",
    "Un concepto importante en machine learning es el compromiso entre sesgo y varianza (bias-variance tradeoff).\n",
    "Los modelos con un sesgo grande no presentan suficiente complejidad para los datos dados y hay tendencia al\n",
    "subajuste (underfit), mientras que los modelos con varianza alta sobreajustan (overfit) los datos de entrenamiento.\n",
    "\n",
    "In esta parte usted debe graficar curvas de errores de entrenamiento y prueba para diagnosticar problemas de\n",
    "sesgo versus varianza.\n",
    "\n",
    "\n",
    "### 2.1 Curvas de aprendizaje (learning curves)\n",
    "Usted implementará un código para generar curvas de aprendizaje, las cuales serán útiles en la depuración del algoritmo.\n",
    "Recuerde que las curvas de aprendizaje durante entrenamiento y valización cruzada (cross validation) como función\n",
    "del tamaño de los datos de entrenamiento. Usted debe completar el código en la functión `learningCurve` en la siguiente\n",
    "celda, de forma que retorne un vector con los errores para los datos de entrenamiento y validación cruzada. \n",
    "\n",
    "Para graficar la curva de entrenamiento necesitamos datos de entrenamiento y validación cruzada para tamaños de\n",
    "datos diferentes. Para obtener datos de entrenamiento diferentes  usted debe elegir subconjuntos distintos del\n",
    "conjunto original de entrenamiento `X`. Especificamente, para un conjunto de entrenamiento de tamaño $i$, usted\n",
    "debe usar primero $i$ muestras ( es decir,  `X[:i, :]` y  `y[:i]`).\n",
    "\n",
    "\n",
    "Puede usar la función `trainLinearReg` (mediante el llamado a  `utils.trainLinearReg(...)`) paraa encontrar los \n",
    "parámetros $\\theta$. Note que  `lambda_` se pasa como parámetro de la función `learningCurve` .\n",
    "Luego del aprendizaje de los parámetros $\\theta$ usted debe calcular el error en los conjuntos de entrenamiento\n",
    "y cross validación. Recuerede que el error de entrenamiento para el conjunto se define como\n",
    "\n",
    "\n",
    "$$ J_{\\text{train}} = \\frac{1}{2m} \\left[ \\sum_{i=1}^m \\left(h_\\theta \\left( x^{(i)} \\right) - y^{(i)} \\right)^2 \\right] $$\n",
    "\n",
    "En particular, que el entrenamiento no incluye el término de regularización. Una forma de calcular el error de entrenamiento\n",
    "es mediante el uso de la función de costo haciendo $\\lambda=0$ solo en el cálculo del error de entrenamiento y validación\n",
    "cruzada. Cuando se calcula el error de entrenamiento se usa el subconjunto de entrenamiento ( es decir,  `X[:n,:]` y `y[:n]`)\n",
    "en vez de todo el conjunto de entrenamiento. Sin embargo, para el error de validación cruzadad lo debe hacer sobre\n",
    "todo el conjunto de validación cruzadad. Debes almacenar los errores en los vectores de errores de entrenamiento y validación.\n",
    "\n",
    "\n",
    "\n",
    "<a id=\"func2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningCurve(X, y, Xval, yval, lambda_=0):\n",
    "    \"\"\"\n",
    "    Genera los errores de entrenamiento y validación cruzada, los cuales son\n",
    "    usados para graficar la curva de aprendizaje. Retorna los errores de\n",
    "    entrenamiento y validación cruzadad para la curva de aprendizaje.\n",
    "    \n",
    "    En esta función usted estima los errores de entrenamiento y prueba\n",
    "    para datos de tamaños desde 1 hasta m. En la práctica, cuando se trabaja\n",
    "    con datos más grandes, usted lo puede lograr con intervalos mayores.\n",
    "    \n",
    "    \n",
    "    Paràmetros\n",
    "    ----------\n",
    "    X : arreglo\n",
    "        Los datos de entrenamiento. Una matriz de tamaño (m x n + 1) donde\n",
    "        m es el númereo total de muestras y n es el número de atributos antes\n",
    "        de agregar el término de sesgo (bias).\n",
    "        \n",
    "    \n",
    "    y : arreglo\n",
    "        Etiquetas para cada dato de entrada. Es un vector de tamaño (m, ).\n",
    "        \n",
    "    \n",
    "    Xval : arreglo\n",
    "        El conjunto para validación cruzada. Una matriz de tamaño (m_val x n+1=\n",
    "        donde m es el número total de muestras y n es el número de atributos antes\n",
    "        de agregar el sesgo.\n",
    "       \n",
    "    yval : arreglo\n",
    "        Las etiquetas correspondientes a los puntos de validación cruzada.\n",
    "        Un vector de tamaño (m_val, ).\n",
    "    \n",
    "    lambda_ : float, opcional\n",
    "        Parámetro de regularización\n",
    "    \n",
    "    Returna\n",
    "    -------\n",
    "    error_trai : arreglo\n",
    "        Un vector de tamaño m.  error_train[i] contiene el error de entrenamiento\n",
    "        de la muestra i.\n",
    "    \n",
    "    error_val : arreglo\n",
    "        Un vector de tamaño m_val. error_val[i]  contiene el error de la validación\n",
    "        para la muestra i\n",
    "        \n",
    "        \n",
    "    Instrucciones:\n",
    "    ------------\n",
    "    \n",
    "    Llene la función, la cual debe retornar los errores de entrenamiento\n",
    "    en error_train y los errores de validación cruzada en error_val.  Es \n",
    "    decir error_train[i] y error_val[i] deberían arrojar los errores obtenidos\n",
    "    en la muestra i.\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    Notas:\n",
    "    -----\n",
    "     - Inicialmente evalua el vector training_error en las primeras i\n",
    "      muestras. Es decir X[:i, :] y y[:i].\n",
    "      \n",
    "      - Para la validación cruzada usted deve evaluar todo\n",
    "      el conjunto correspondiente a la validación cruzada (Xval y yval)\n",
    "    \n",
    "     - Si está usando la función de costo (linearRegCostFunction) para calcular\n",
    "       el error de entrenamiento y validación cruzada, debe llamar la función con\n",
    "       lambda=0. Sin embargo usted todavia necesita usar lambda durante entrenamiento\n",
    "       para obtener los parámetros theta. \n",
    "     \n",
    "     \n",
    "    \n",
    "    Ayuda\n",
    "    ----\n",
    "    Usted puede iterar sobre las muetras con el siguiente código:\n",
    "     \n",
    "           for i in range(1, m+1):\n",
    "               # Calcule errores de entrenar/validar errors usando muestras de entrenamiento\n",
    "               # X[:i, :] and y[:i], almacenar en\n",
    "               # error_train[i-1] and error_val[i-1]\n",
    "               ....  \n",
    "    \"\"\"\n",
    "    # Número de muestras de entrenamiento\n",
    "    m = y.size\n",
    "\n",
    "    # necesita retornar estos correctamento\n",
    "    error_train = np.zeros(m)\n",
    "    error_val   = np.zeros(m)\n",
    "\n",
    "    # ====================== SU CÓDIGO ACÁ ======================\n",
    "         \n",
    "\n",
    "        \n",
    "    # =============================================================\n",
    "    return error_train, error_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando termine la implementación de la función  `learningCurve`, la próxima celda debe producir la figura\n",
    "\n",
    "![](Figures/learning_curve.png)\n",
    "\n",
    "En la figura de aprendizaje usted puede observar el error de entrenamiento  incrementando \n",
    "con el número de muestras. Esto refleja un sesgo alto en el modelo  ' la regresion lineal es demasiado simple y no\n",
    "puede ajustarse a los datos bien. En la próxima sección usted implementará la regresión polinomial para mejor\n",
    "ajustar el modelo a los datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "Xval_aug = np.concatenate([np.ones((yval.size, 1)), Xval], axis=1)\n",
    "error_train, error_val = learningCurve(X_aug, y, Xval_aug, yval, lambda_=0)\n",
    "\n",
    "pyplot.plot(np.arange(1, m+1), error_train, np.arange(1, m+1), error_val, lw=2)\n",
    "pyplot.title('Learning curve for linear regression')\n",
    "pyplot.legend(['Train', 'Cross Validation'])\n",
    "pyplot.xlabel('Number of training examples')\n",
    "pyplot.ylabel('Error')\n",
    "pyplot.axis([0, 13, 0, 150])\n",
    "\n",
    "print('# Training Examples\\tTrain Error\\tCross Validation Error')\n",
    "for i in range(m):\n",
    "    print('  \\t%d\\t\\t%f\\t%f' % (i+1, error_train[i], error_val[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "\n",
    "## 3 Regresión polinomial\n",
    "\n",
    "El  problema con la regresión lineal es que es muy simple para los datos y el resultado\n",
    "subestima (sesgo alto) la soluciòn,  En esta parte agregamos mas atributos. Para la regresión polinòmica la hipòtesis toma la forma\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "h_\\theta(x)  &= \\theta_0 + \\theta_1 \\times (\\text{waterLevel}) + \\theta_2 \\times (\\text{waterLevel})^2 + \\cdots + \\theta_p \\times (\\text{waterLevel})^p \\\\\n",
    "& = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_p x_p\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "Note que por definición $x_1 = (\\text{waterLevel})$, $x_2 = (\\text{waterLevel})^2$ , $\\cdots$, $x_p =\n",
    "(\\text{waterLevel})^p$, encontramos un modelo de regresión lineal donde los atributos son potencias del valor inicial (waterLevel).\n",
    "\n",
    "Ahora usted debe agregar mas atributos correspondientes a potencias del atributo $x$ en los datos. Su tarea en esta parte es completar el código en la función\n",
    " `polyFeatures` en la siguiente celda. La función debe mapear el conjunto original de datos $X$ de tamaño $m \\times l$ a potencias superiores. Especificamente,\n",
    "cuando un conjunto de datos de entrenamiento $X$ de tamaño $m \\times l$ se pasa a una funciòn, la función debería retornar una matriz $m \\times p$ \n",
    " `X_poly`, donde la columna 1 contiene los valores originales de X, la columna 2 contiene los valores $X^2$, la columna 3 los valores $X^3$, etc.\n",
    " \n",
    "\n",
    "\n",
    "<a id=\"polyFeatures\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyFeatures(X, p):\n",
    "    \"\"\"\n",
    "    Mape X (vector) a la potencia p\n",
    "    \n",
    "    Paràmetros\n",
    "    ----------\n",
    "    X : arreglo\n",
    "        un vector de tamaño m, donde  m es el nùmero de muestras.\n",
    "    \n",
    "    p : int\n",
    "        potencia del polinomio. \n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    X_poly : arreglo\n",
    "        Una matriz de tamaño (m x p ) donde p es un polinomio\n",
    "        la potencia m es el nùmero de muestras. Es decir,\n",
    "    \n",
    "        X_poly[i, :] = [X[i], X[i]**2, X[i]**3 ...  X[i]**p]\n",
    "    \n",
    "    Instrucciones\n",
    "    ------------\n",
    "    Dado un vector X, retorna una matriz X_poly donde la columna p\n",
    "    de X contiene los valores de X a la potencia p.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Necesita retornar los siguientes valores correctamente\n",
    "    X_poly = np.zeros((X.shape[0], p))\n",
    "\n",
    "    # ====================== SU CÓDIGO ACÁ ======================\n",
    "\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usted tiene una funciòn que mapea atributos a una dimensiòn superior. La próxima celda se aplica a los datos de entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 8\n",
    "\n",
    "# Mapea X a atributos polinomiales y normaliza\n",
    "X_poly = polyFeatures(X, p)\n",
    "X_poly, mu, sigma = utils.featureNormalize(X_poly)\n",
    "X_poly = np.concatenate([np.ones((m, 1)), X_poly], axis=1)\n",
    "\n",
    "# Mapea X_poly_test y normaliza suando mu y sigma\n",
    "X_poly_test = polyFeatures(Xtest, p)\n",
    "X_poly_test -= mu\n",
    "X_poly_test /= sigma\n",
    "X_poly_test = np.concatenate([np.ones((ytest.size, 1)), X_poly_test], axis=1)\n",
    "\n",
    "# Mapea X_poly_val y normaliza (usando mu y sigma=\n",
    "X_poly_val = polyFeatures(Xval, p)\n",
    "X_poly_val -= mu\n",
    "X_poly_val /= sigma\n",
    "X_poly_val = np.concatenate([np.ones((yval.size, 1)), X_poly_val], axis=1)\n",
    "\n",
    "print('Normalized Training Example 1:')\n",
    "X_poly[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Aprendizaje de rergresión polinomial\n",
    "\n",
    "Luego de completar la función  `polyFeatures`, procedemos a entrenar la regresiòn polinomial usando la función de costo de la regresiòn lineal.\n",
    "\n",
    "Tenga en cuenta que aunque tengamos términos polinomiales en nuesto vector de atributos, el problema que estamos resolviendo es aún lineal en $\\theta$.\n",
    "Los tèrminos polinomiales se convierten en atributos que se pueden usar para regresiòn lineal. Usamos la misma funciòn de costo y gradiente que usted escribiò\n",
    "arriba.\n",
    "\n",
    "Para esta parte del ejercicio, usted usará un polinomio de grado 8. Si corremos el entrenamiento directamente en los datos proyectados, podríamos tener\n",
    "problemas debido a escalas (por ejemplo, si $x=40$ entones $x_8 = 40^8=6.5 \\times 10^{12}$. Por esta razòn necesitamos normalizaciòn.\n",
    "\n",
    "\n",
    "Antes de aprender los paràmetros $\\theta$ para la regresiòn polinòmica primeros llamamos `featureNormalize` y normalizamos los atributos, almacenando\n",
    "$\\mu$, $\\sigma$. Esta función ya está implementada en `utils.py`.\n",
    "\n",
    "\n",
    "Luego de aprender el paràmetro $\\theta$ useted debe ver los dos gráficos generados para regresión polinómica con $\\lambda=0$, que deben ser parecidas\n",
    "a las mostradas acá.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"Figures/polynomial_regression.png\"></td>\n",
    "        <td><img src=\"Figures/polynomial_learning_curve.png\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Se puede observar que el ajuste polinomial sigue los puntos muy bien, lo cual produce un error de entrenamiento bajo. La figura en la derecha\n",
    "muestra que el error de aprendizaje esencialmente es 0 para todas las muestras de entrenamiento. Sin embargo, el ajuste polinomial es muy\n",
    "complicado y presenta problemas en los extremos. Esto es un indicador de sobreajuste en los datos de entrenamiento. Es decir el modelo\n",
    "no generaliza bien. \n",
    "\n",
    "\n",
    "Para entender mejor los problemas con el modelo no regularizado ($\\lambda=0$) usted puede ver que la curva de aprendizaje muestra el mismo efecto\n",
    "con error de entrenamiento bajo, sin embargo el error de validaciòn cruzada es alto. Hay una brecha entre los errors entrenamiento y los de validación cruzada,\n",
    "lo cual indica una varianza alta en el problema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0\n",
    "theta = utils.trainLinearReg(linearRegCostFunction, X_poly, y,\n",
    "                             lambda_=lambda_, maxiter=55)\n",
    "\n",
    "# grafique los datos y ajuste\n",
    "pyplot.plot(X, y, 'ro', ms=10, mew=1.5, mec='k')\n",
    "\n",
    "utils.plotFit(polyFeatures, np.min(X), np.max(X), mu, sigma, theta, p)\n",
    "\n",
    "pyplot.xlabel('Change in water level (x)')\n",
    "pyplot.ylabel('Water flowing out of the dam (y)')\n",
    "pyplot.title('Polynomial Regression Fit (lambda = %f)' % lambda_)\n",
    "pyplot.ylim([-20, 50])\n",
    "\n",
    "pyplot.figure()\n",
    "error_train, error_val = learningCurve(X_poly, y, X_poly_val, yval, lambda_)\n",
    "pyplot.plot(np.arange(1, 1+m), error_train, np.arange(1, 1+m), error_val)\n",
    "\n",
    "pyplot.title('Polynomial Regression Learning Curve (lambda = %f)' % lambda_)\n",
    "pyplot.xlabel('Number of training examples')\n",
    "pyplot.ylabel('Error')\n",
    "pyplot.axis([0, 13, 0, 100])\n",
    "pyplot.legend(['Train', 'Cross Validation'])\n",
    "\n",
    "print('Polynomial Regression (lambda = %f)\\n' % lambda_)\n",
    "print('# Training Examples\\tTrain Error\\tCross Validation Error')\n",
    "for i in range(m):\n",
    "    print('  \\t%d\\t\\t%f\\t%f' % (i+1, error_train[i], error_val[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una forma de combatir el sobreajuste (varianza alta) es mediante regularización. En la próxima sección, usted va a tratar paràmetros diferentes\n",
    "de $\\lambda$ para ver como la regularizaciòn produce un mejor modelo.\n",
    "\n",
    "\n",
    "### 3.2 Ajuste del parámetro de regularización.\n",
    "\n",
    "En esta sección usted verà como el parámetro de regularización afecta la relación de sesgo-varianza de la regresión polinomial. Usted debe modificar\n",
    "el parámetro y tratar $\\lambda = 1, 100$. Para cada uno de estos valores, el programa debe generar un ajuste del polinomio a los datos y asi una curva\n",
    "de aprendizaje.\n",
    "\n",
    "$Para $\\lambda = 1$, los gráficos se deben ver como la figura abajo. Usted debería ver un ajuste polinomial que sigue los datos bien (izquierda) y una\n",
    "curva de aprendizaje (derecha) que muestra que tanto el error de entrenamientco como el de validación cruzada convergen a un valor bajo. Esto muestra\n",
    "que  $\\lambda = 1$ proporciona un modelo que no tiene, ni sesgo, ni varianza altos. En efecto, este muestra una buena relaciòn costo beneficio entre\n",
    "sesgo y varianza. \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"Figures/polynomial_regression_reg_1.png\"></td>\n",
    "        <td><img src=\"Figures/polynomial_learning_curve_reg_1.png\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Para $\\lambda=100$ (figura abajo) vemos que la curva no sigue de cerca los puntos. En este caso, la regularizaciòn es muy alta y el modelo tiene un sesgo\n",
    "alto. No puede seguir bien los datos. \n",
    "\n",
    "\n",
    "![](Figures/polynomial_regression_reg_100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "### 3.3 Selección de  $\\lambda$ mediante un conjunto de validaciòn cruzada\n",
    "\n",
    "De las partes anteriores de este ejercicio usted ha observado que el valor de $\\lambda$ puede afectar significativamente los resultados de regresión polinomial\n",
    "regularizada en el contexto del compromiso de  sesgo vs varianza. En particular, un modelo sin regularización $(\\lambda=0)$ produce un buen ajuste\n",
    "de los datos de entrenamiento a la curva. Sin embargo este modelo no generaliza bien a datos por fuera de los datos de entrenamiento. En el otro polo,\n",
    "una regularización con ($\\lambda=100$) no produce un buen ajuste entre los datos y el modelo. Una buena selección de $\\lambda$ es $\\lambda=1$. Esta\n",
    "provee un buen ajuste entre los datos y el modelo. \n",
    "\n",
    "En esta sección usted debe implementar un método automático para seleccionar $\\lambda$. Concretamente, usted va a usasr validación cruzada para evaluar\n",
    "que tam bien $\\lambda$ ajusta los datos al modelo. Luego de seleccionar el mejor $\\lambda$ usando el conjunto de validación cruzada, podemos evaluar el modelo\n",
    "en datos de prueba para estimar que tan bien el modelo generaliza a datos externos al entrenamiento. \n",
    "\n",
    "Su tarea es completar el código en la función `validationCurve`. Especìficamente usted debe usar la función  `utils.trainLinearReg` para entrenar el model\n",
    "usando diferentes valores de $\\lambda$ y la evaluación en datos de entrenamientos y validación. Usted debe probar los siguientes $\\lambda$ : {0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10}.\n",
    "<a id=\"validationCurve\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validationCurve(X, y, Xval, yval):\n",
    "    \"\"\"\n",
    "    Generar los errores de entrenamiento y validación necesarios\n",
    "    para graficar las curvas de validación que usamos para seleccionar lambda.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    X : arreglo\n",
    "        Los datos de entrenamiento. Matriz con tamaño (m x n ) donde \n",
    "        m es el nùmero total de muestas y n es el nùmero de atributos\n",
    "        incluyendo atributos polinomiales.\n",
    "        \n",
    "       \n",
    "    \n",
    "    y : arreglo\n",
    "        Las etiquetas correspondientes a los datos. Un vector\n",
    "        de tamaño (m, )\n",
    "        \n",
    "    Xval : arreglo\n",
    "        Los dadtos de validaciòn. Una matriz de tamaño (n_val x n) donde\n",
    "        m es el número total de muestras de validación y n es sel número\n",
    "        de atributos incluyendo atributos polinomiales. \n",
    "    \n",
    "    \n",
    "    yval : arreglo\n",
    "        Las etiquetas correspondientes a los datos de validadación.\n",
    "        El tamaño es (m_val, )\n",
    "        \n",
    "    \n",
    "    \n",
    "    Retorno\n",
    "    -------\n",
    "    lambda_vec : lista\n",
    "        Los valores de regularización que se usan en la validación\n",
    "        cruzada. \n",
    "      \n",
    "    \n",
    "    error_train : lista\n",
    "        El error de entrenamiento paara cadad valor del parámetro\n",
    "        de regularización.\n",
    "       \n",
    "    error_val : lista\n",
    "        El error de validación calculado para cada parámetro\n",
    "        de regularización. \n",
    "       \n",
    "    Instrucciones:\n",
    "    ------------\n",
    "    Complete esta función para que retorne los errores de entrenamiento y\n",
    "    validación en `error_train y `error_val`. El vector `lambda_vec` \n",
    "    contiene diferentes parámetros de laambdad para usar en cada cálculo\n",
    "    de errores. Es decir, `error_train[i]`, y `error_val[i]` deben\n",
    "    producir los errores luego del entrenamiento con `lambda_ = lambda_vec[i]`.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Nota\n",
    "    ----\n",
    "    Usted debe buscar, en un ciclo,   lambda_vec con lo siguiente\n",
    "    \n",
    "          for i in range(len(lambda_vec))\n",
    "              lambda = lambda_vec[i]\n",
    "              # calcule erroes de entrenamiento y validaciòn  \n",
    "              # regresion con parámetro de regularización lambda.\n",
    "              # Debe guardar el resultado en error_train[i]\n",
    "              # y error_val[i]\n",
    "              ....\n",
    "    \"\"\"\n",
    "    # Valores seleccionados de lambda. No cambie esto.\n",
    "    lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]\n",
    "\n",
    "    # You need to return these variables correctly.\n",
    "    error_train = np.zeros(len(lambda_vec))\n",
    "    error_val = np.zeros(len(lambda_vec))\n",
    "\n",
    "    # ====================== SU CÓDIGO ACÁ ======================\n",
    "\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    return lambda_vec, error_train, error_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de completar el código, la siguiente celda corre la función y grafica la curva de error de validación cruzada contra $\\lambda$. Esto\n",
    "nos permite seleccionar cual $\\lambda$ debe usar. Usted debería tener una gráfica similar a la que sigue abajo.\n",
    "\n",
    "![](Figures/cross_validation.png)\n",
    "\n",
    "En esta figura podemos observar que el mejor valor de $\\lambda$ esta al rededor de 3. Debido a la aletoriedad\n",
    "en la partición de entrenamiento y validación el error de validación cruzada puede ser algunas veces más bajo\n",
    "que el de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec, error_train, error_val = validationCurve(X_poly, y, X_poly_val, yval)\n",
    "\n",
    "pyplot.plot(lambda_vec, error_train, '-o', lambda_vec, error_val, '-o', lw=2)\n",
    "pyplot.legend(['Train', 'Cross Validation'])\n",
    "pyplot.xlabel('lambda')\n",
    "pyplot.ylabel('Error')\n",
    "\n",
    "print('lambda\\t\\tTrain Error\\tValidation Error')\n",
    "for i in range(len(lambda_vec)):\n",
    "    print(' %f\\t%f\\t%f' % (lambda_vec[i], error_train[i], error_val[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
