{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio de programación  8:\n",
    "# Detección de Anomalías y Sistemas de Recomendación\n",
    "\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En este ejercicio usted implementará el algoritmo de detección de anomalías\n",
    "y las applicará para detectar fallas en servidores en un red. En la segunda parte\n",
    "usará el filtro colaborativo para construir un sistema de recomendación de películas.\n",
    "Antes de comenzar le recomendamos revisar las notas de clase.\n",
    "\n",
    "Toda la información requerida para resolver esta tarea está en este cuadernillo. Además\n",
    "todo el código que implementará también está en este cuadernillo. \n",
    "\n",
    "Antes de comenzar necesitará importar todas las librerías requeridas para el ejercicio. Usted podría requerir [`numpy`](http://www.numpy.org/)  para las operaciones entre arreglos y matrices,  [`matplotlib`](https://matplotlib.org/) \n",
    "para graficar, y [`scipy`](https://docs.scipy.org/doc/scipy/reference/)  para cómputos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para manipulación de caminos y archivos\n",
    "import os\n",
    "\n",
    "# para cálculos numéricos\n",
    "import numpy as np\n",
    "\n",
    "# para graficar\n",
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "\n",
    "# librería de optimización\n",
    "from scipy import optimize\n",
    "\n",
    "# para cargar el archivo en formato MATLAB\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# library written for this exercise providing additional functions for assignment submission, and others\n",
    "# librería con funciones adicionales que se podrían necesitar\n",
    "import utils\n",
    "\n",
    "# grafique dentro del cuadernillo\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Detección de Anomalías \n",
    "\n",
    "En este ejercicio implementará el algoritmo de detección de anomalías para detectar el comportamiendo de servidores de computación. Los atributos miden el  rendimiento (mb/s) y latencia (ms) de la respuesta de cada servidor. Mientras los\n",
    "servidores estan operando, usted recolecta $m=307$ muestras acerca del comportamiento, de forma que tiene unos datos\n",
    "no supervisados (sin etiquetas)  $\\{x^{(1)}, \\dots, x^{(m)}\\}$. Usted sospecha que la gran mayoría de estas muestras son\n",
    "\"normales\" (no son anomalías), pero podrían haber algunas muestras de servidores actuando anómalamente con este conjunto de datos. \n",
    "\n",
    "Usted usará un modelo Gausiano para detectar anomalías en su conjunto de datos.  Inicialmente comienza con un conjunto 2D de datos que le permitirá visualizar lo que el algoritmo hace.  Usted ajusta el conjunto de datos a una distribución Gausiana\n",
    "y encuentra los valores que tienen probabilidad baja y considerados como anómalos. Luego de esto usted aplica el algoritmo de detección de anomalías a un conjunto de más dimensiones. \n",
    "\n",
    "Comenzamos el ejercicio usando un conjunto de datos pequeño y fácil de visualizar. Nuestro ejemplo consiste en 2 estadísticas\n",
    "de servidores de red a lo largo de varias máquinas: la latencia y el rendimiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  cargamos los datos\n",
    "data = loadmat(os.path.join('Data', 'ex8data1.mat'))\n",
    "X, Xval, yval = data['X'], data['Xval'], data['yval'][:, 0]\n",
    "\n",
    "#  visualizamos este ejemplo\n",
    "pyplot.plot(X[:, 0], X[:, 1], 'bx', mew=2, mec='k', ms=6)\n",
    "pyplot.axis([0, 30, 0, 30])\n",
    "pyplot.xlabel('Latency (ms)')\n",
    "pyplot.ylabel('Throughput (mb/s)')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Distribución Gausiana\n",
    "\n",
    "Para ejecutar la detección de anomalías usted necesita primero ajustar un modelo a la distribución de los datos. \n",
    "Dado un conjunto de datos $\\{x^{(1)}, \\dots, x^{(m)} \\}$ (donde  $x^{(i)} \\in \\mathbb{R}^n$ ), se debe estimar\n",
    "la distribución Gausiana para cada uno de los atributos $x_i$. Para cada atributo $i=1, \\dots n$, necesita calcular\n",
    "los parámetros $\\mu_i$ y $\\sigma_i^2$ que se ajustan a los datos en la \n",
    "dimensión $i$, $\\{ x_i^{(1)}, \\dots, x_i^{(m)} \\}$ (la dimensión $i$\n",
    "de cada muestra).\n",
    "\n",
    "\n",
    "La distribución Gausiana está data por\n",
    "\n",
    "$$ p\\left( x; \\mu, \\sigma^2 \\right) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{\\left(x-\\mu\\right)^2}{2\\sigma^2}},$$\n",
    "donde $\\mu$ es la media y  $\\sigma^2$ la varianza.\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "### 1.2 estimado de parámetros Gausianos\n",
    "\n",
    "Usted puede estimar los parámetros $\\left( \\mu_i, \\sigma_i^2 \\right)$, \n",
    "del atributo $i$ mediante el uso de las siguientes ecuaciones:\n",
    "\n",
    "media\n",
    "$$ \\mu_i = \\frac{1}{m} \\sum_{j=1}^m x_i^{(j)},$$\n",
    "\n",
    "varianza\n",
    "\n",
    "$$ \\sigma_i^2 = \\frac{1}{m} \\sum_{j=1}^m \\left( x_i^{(j)} - \\mu_i \\right)^2.$$\n",
    "\n",
    "Su tarea es completar el código `estimateGaussian`.  Esta función asume\n",
    "como entrada la matriz `X`  y debería sacar el vector n-dimensional \n",
    "`mu`, que guarda las medias de cada una de los $n$ atributos y \n",
    "el vector n-dimensional   `sigma2` contiene las varianzas de cada uno de los atributos.\n",
    "Usted puede impelentar esto usando un bucle for sobre cada atributo y muestra (aunque una\n",
    "implementación vecrtorizada podría ser más eficiente; siéntase libr de tratar una implementación\n",
    "vectorizada si así lo prefiere.\n",
    "\n",
    "<a id=\"estimateGaussian\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateGaussian(X):\n",
    "    \"\"\"\n",
    "    Esta función estima los parámetros de una distribución Gaussiana\n",
    "    usando los datos suminstrados.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    X : arreglo\n",
    "        los datos de tamaño (m x n) con m puntos n-dimensionales\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    mu : arreglo\n",
    "        Un vector de tamaño (n,) con las medias en cada dimensón.\n",
    "    \n",
    "    sigma2 : arreglo\n",
    "        Un vector de tamaño  (n,) con las varianzas en cada dimensión.\n",
    "    \n",
    "    Instrucciones\n",
    "    ------------\n",
    "    Calcule la media de los datos y las varianzas.\n",
    "    In particular ,mu[i] debe contener la media de\n",
    "    los datos para el atributo $i$ y sigma2[i]\n",
    "    debe contener la varianza para el atributo i.\n",
    "    \"\"\"\n",
    "    # variables útiles\n",
    "    m, n = X.shape\n",
    "\n",
    "    # debe retornar estos valores correctamente\n",
    "    mu = np.zeros(n)\n",
    "    sigma2 = np.zeros(n)\n",
    "\n",
    "    # ====================== Su Código Acá ======================\n",
    "\n",
    "    \n",
    "    # =============================================================\n",
    "    return mu, sigma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez halla completado el código en `estimateGaussian`, la celda siguiente visualiza los contornos de\n",
    "la distribución Gausiana ajustada. Debería obenter una figura como la siguiente.\n",
    "\n",
    "![](Figures/gaussian_fit.png)\n",
    "\n",
    "De la figura, usted puede ver las mayoría de las muestras en la región de más alta propbabilidad, mientras\n",
    "que las muestras atípicas están en regiones de baja probabilidad. \n",
    "\n",
    "Para la visualización del ajuste Gausiano, primero estimamos los parametros de la distribución y luego\n",
    "calculamos la probabilidad para cada uno de los puntos. Luego visualizamos la distribución en general donde\n",
    "cada punto se localiza de acuerdo a la distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Estime mu y sigma2\n",
    "mu, sigma2 = estimateGaussian(X)\n",
    "\n",
    "#  Retorna la densidad multivariada de la normal para cada punto (fila) de X\n",
    "p = utils.multivariateGaussian(X, mu, sigma2)\n",
    "\n",
    "#  Visualizamos el ajuste\n",
    "utils.visualizeFit(X,  mu, sigma2)\n",
    "pyplot.xlabel('Latency (ms)')\n",
    "pyplot.ylabel('Throughput (mb/s)')\n",
    "pyplot.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "### 1.3 Seleccione el umbral,  $\\varepsilon$\n",
    "\n",
    "Ahora que ya tiene los parámetros Gausianos, puede investigar que muestras tienen una alta probabilidad\n",
    "dada la distribución y que muestras tienen una baja probabilidad. Las muestras de baja probabilidad son \n",
    "las más factibles de ser anómalas. Una forma de determinar que muestras son anómalas es mediante la}\n",
    "selección de un umbral basado en un conjunto de validación cruzada.  En esta parte del ejercicio usted\n",
    "implementará un algoritmo para seleccionar el umbral $\\varepsilon$ mediante el uso del $F_1$ score,\n",
    "en el conjunto de validación cruzada. \n",
    "\n",
    "Usted debe ahora completar ls función  `selectThreshold`.  Para esto, usaremos una validación cruzada\n",
    "en el conjunto  $\\{ (x_{cv}^{(1)}, y_{cv}^{(1)}), \\dots, (x_{cv}^{(m_{cv})}, y_{cv}^{(m_{cv})})\\}$, \n",
    "donde la etiqueta $y=1$ corresponde a la muestra anómala, y $y=0$ corresponde a una muestra normal. Para\n",
    "cada muestra de validación cruzada, calculamos  $p\\left( x_{cv}^{(i)}\\right)$. El vector de todas las probabilidades\n",
    "s $p\\left( x_{cv}^{(1)}\\right), \\dots, p\\left( x_{cv}^{(m_{cv})}\\right)$  se le pasa a `selectThreshold` en el \n",
    "vector `pval`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La  función `selectThreshold` debería retornar dos valores el primero es el umbral seleccionado\n",
    "$\\varepsilon$. Si una muestra $x$ tiene baja probabilidad $p(x) < \\varepsilon$, entonces se considera una anomalía.\n",
    "El segundo es el $F_1$ score, que nos dice que tan bien estamos estimando los valores calculados con respecto a los reales, de acuerdo al umbral establecido. Para muchos umbrales $\\varepsilon$, debe comparar las diferentes\n",
    "$F_1$ medidas basado en el la clasificación de las muestras.\n",
    "\n",
    "El $F_1$ score se calcula usando la precisión ($prec$) y la sensibilidad (recall, $rec$).\n",
    "\n",
    "$$ F_1 = \\frac{2 \\cdot prec \\cdot rec}{prec + rec}, $$\n",
    "\n",
    "Usted calcula la precición y sensibilidad mediante las fórmulas\n",
    "$$ prec = \\frac{tp}{tp + fp}  $$ \n",
    "\n",
    "$$ rec = \\frac{tp}{tp + fn} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde:\n",
    "\n",
    "- $tp$ es el número de verdaderos positivos (true positives): La etiqueta real dice que es una anomalía y\n",
    "el algoritmo  correctmente la clasifica como tal.\n",
    "\n",
    "-  $fp$ es el número de falsos positivos: la etiqueta real dice que no es una anomalía, pero el algoritmo\n",
    "incorrectamente lo clasifica como anomalía.\n",
    "- $fn$ es el número de falsos negativos:  la etiqueta real dice que es una anomalía, pero el algoritmo\n",
    "- incorrectamente lo calsifica como normal.\n",
    "\n",
    "En el código suminstrado `selectThreshold`, hay un ciclo que prueba muchos umbrales $\\varepsilon$\n",
    "y selecciona el mejor $\\varepsilon$ basado en el $F_1$ score. Usted debe completar el código `selectThreshold`.\n",
    "Puede implementar el cómputo de $F_1$ usando un bucle for sobre todas las muestras de validación cruzada\n",
    "(para calcular los valores de $tp$, $fp$, $fn$). Debería tener un `epsilon` cercano a 8.99e-05.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "**Nota de implementación**  :  Con el fin de calcular $tp$, $fp$ y $fn$, podría usar una implementación \n",
    "vectorizada mejor que un bucle sobre las muestras.  Esta se puede implementar usando una prueba de igualdad\n",
    "en numpy entre un vector y un escalar. Si tiene varias muestras vinarias en un vector binario n-dimensional\n",
    "$v \\in \\{0, 1\\}^n$, puede encontrar cuantas muestras en el vector son 0 usando: `np.sum(v==0)` . \n",
    "Tambien puede aplicar un operador lógico sobre los vectores binarios. Por ejemplo, sea  `cvPredictions` \n",
    "un vector binario de tamaño $x_{cv}^{(i)}$ una anomalía, y 0 si no. Usted puede, por ejemplo, calcular\n",
    "el número de falsos positivos usando: `fp = np.sum((cvPredictions == 1) & (yval == 0))`.\n",
    "</div>\n",
    "<a id=\"selectThreshold\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectThreshold(yval, pval):\n",
    "    \"\"\"\n",
    "    Encuentre el mejor umbral (epsilon) para usar en la selección de\n",
    "    muestras anómalas basdo en resultados del conjunto de validación \n",
    "    cruzada y las etiquetas de referencia reales.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    yval : arreglo\n",
    "        El arreglo de valores reales, de tamaño (m, ).\n",
    "    \n",
    "    pval : arreglo\n",
    "        El vector precalculado de probabilidades basado en la media mu y la varianza sigma2.\n",
    "        Tiene tamaño (m, ).\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    bestEpsilon : arreglo\n",
    "        Un vector de tamaño (n, ) correspondiente al valor del umbral.\n",
    "    \n",
    "    bestF1 : float\n",
    "        El valor del mejor F1 score.\n",
    "    \n",
    "    Instrucciones\n",
    "    ------------\n",
    "    Calcule el F1 score escogiendo epsilon como el umbral y coloque\n",
    "    el valor in F1. El código al final del ciclo compara el F1 score\n",
    "    para esta escogencia de epsilon y lo asigna como el mejor epsilon\n",
    "    si es mejor que el la elección acual de epsilon.\n",
    "    \n",
    "    Notas\n",
    "    -----\n",
    "    Usted puede usar las predicciones =(pval < epsilon) para obtener\n",
    "    el vector de 0s y 1s en la predicción de muestras atípicas. \n",
    "    \"\"\"\n",
    "    bestEpsilon = 0\n",
    "    bestF1 = 0\n",
    "    F1 = 0\n",
    "   \n",
    "    for epsilon in np.linspace(1.01*min(pval), max(pval), 1000):\n",
    "        # ====================== Su Código Acá =======================\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        # =============================================================\n",
    "        if F1 > bestF1:\n",
    "            bestF1 = F1\n",
    "            bestEpsilon = epsilon\n",
    "\n",
    "    return bestEpsilon, bestF1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez halla completado el código en `selectThreshold`, la próxima celdda calcula la detección de anomalías y \n",
    "las marca con  un círculo rojo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = utils.multivariateGaussian(Xval, mu, sigma2)\n",
    "\n",
    "epsilon, F1 = selectThreshold(yval, pval)\n",
    "print('Best epsilon found using cross-validation: %.2e' % epsilon)\n",
    "print('Best F1 on Cross Validation Set:  %f' % F1)\n",
    "print('   (you should see a value epsilon of about 8.99e-05)')\n",
    "print('   (you should see a Best F1 value of  0.875000)')\n",
    "\n",
    "#  Find the outliers in the training set and plot the\n",
    "outliers = p < epsilon\n",
    "\n",
    "#  Visualize the fit\n",
    "utils.visualizeFit(X,  mu, sigma2)\n",
    "pyplot.xlabel('Latency (ms)')\n",
    "pyplot.ylabel('Throughput (mb/s)')\n",
    "pyplot.tight_layout()\n",
    "\n",
    "#  Dibuje un círculo rojo al rededor de cada muestra anómala.\n",
    "pyplot.plot(X[outliers, 0], X[outliers, 1], 'ro', ms=10, mfc='None', mew=2)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Conjunto con muchas dimensiones\n",
    "\n",
    "La próxima celda corre el algoritmo de detección de anomalías implementado en datos mas realistas y difíciles. \n",
    "En estos datos, cada muestra tiene 11 atributos, los cuales capaturan muchas propiedades de servidores de computación, donde solo unos pocos atributos indican que punto es anómalo. El código usa su código para\n",
    "estimar los parámetros Gausianos ($\\mu_i$ y $\\sigma_i^2$), evalúan las probabilidades para los datos de \n",
    "entrenamiento `X` y validación  `Xval`. Finalmente, usa `selectThreshold`  para encontrar el mejor\n",
    "umbral $\\varepsilon$. Usted debería ver un epsilon cercano a 1.38e-18, y 117 anomalías.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Cargue los datos. Debería tener\n",
    "#  variables X, Xval, yval en su ambiente\n",
    "data = loadmat(os.path.join('Data', 'ex8data2.mat'))\n",
    "X, Xval, yval = data['X'], data['Xval'], data['yval'][:, 0]\n",
    "\n",
    "# Aplicar los mismos pasos para el conjunto grande\n",
    "mu, sigma2 = estimateGaussian(X)\n",
    "\n",
    "#  Entrenamiento\n",
    "p = utils.multivariateGaussian(X, mu, sigma2)\n",
    "\n",
    "#  Validación cruzada.\n",
    "pval = utils.multivariateGaussian(Xval, mu, sigma2)\n",
    "\n",
    "#  Encuentre el mejor umbral\n",
    "epsilon, F1 = selectThreshold(yval, pval)\n",
    "\n",
    "print('Best epsilon found using cross-validation: %.2e' % epsilon)\n",
    "print('Best F1 on Cross Validation Set          : %f\\n' % F1)\n",
    "print('  (you should see a value epsilon of about 1.38e-18)')\n",
    "print('   (you should see a Best F1 value of      0.615385)')\n",
    "print('\\n# Outliers found: %d' % np.sum(p < epsilon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Sistemas de Recomendación\n",
    "\n",
    "En esta parte del ejercicio, usted debe implementar un algoritmo de filtros colaborativos y aplicarlos\n",
    "a un conjunto de calificación de películas ([MovieLens 100k Dataset](https://grouplens.org/datasets/movielens/) \n",
    "de GroupLens Reseach). Este conunto de datos tiene una escala de 1 a 5. Los datos tienen $n_u=943$ usuarios,\n",
    "y $n_m=1682$ películas.\n",
    "\n",
    "En las siguientes partes del ejercicio usted debe implementar la función `cofiCostFunc`  que calcula\n",
    "la función objetivo y gradiente de los filtros colaborativos. Luego de implementar la función de costo y \n",
    "el gradiente, usted debe usar `scipy.optimize.minimize` para aprender los parámetros de los filtros colaborativos. \n",
    "\n",
    "\n",
    "### 2.1 Datos de calificación de películas\n",
    "\n",
    "La próxima celda carga los datos `ex8_movies.mat`,  que generan las variables `Y` y `R`.\n",
    "La matriz `Y` (de tamaño  `num_movies` $\\times$ `num_users`) guarda las calificaciones $y^{(i,j)}$\n",
    "(de 1 a 5).  La matriz binaria `R`  indica donde $R(i,j) = 1$ si el usuario $j$  calificó la película\n",
    "$i$, y $R(i,j)=0$ en caso contrario.  El objeto de los filtros colaborativos es predecir las calificaciones\n",
    "de las películas que los usuarios no han calificado. Es decir, los valores $R(i,j)=0$. Esto permite la recomendación de una película con la mejor predicción al usuario.\n",
    "\n",
    "Para mejor entender la matriz `Y`,  la celda que sigue calcula la calificación media para la primera película\n",
    "(Toy Story) e imprime este valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos\n",
    "data = loadmat(os.path.join('Data', 'ex8_movies.mat'))\n",
    "Y, R = data['Y'], data['R']\n",
    "\n",
    "# Y es una matriz  1682x943 con las calificaciones (1-5) de\n",
    "# 1682 películas y  943 usuarios\n",
    "\n",
    "# R es una matriz  1682x943 matrix, donde  R(i,j) = 1 \n",
    "# si y solo si el usuario j calificó la película i\n",
    "\n",
    "# de la matriz podemos calcular las estadísticas tales como el promedio de calificación.\n",
    "print('Average rating for movie 1 (Toy Story): %f / 5' %\n",
    "      np.mean(Y[0, R[0, :] == 1]))\n",
    "\n",
    "# Podemos \"visualizar\" la matriz de calificaciones graficandola con imshow\n",
    "pyplot.figure(figsize=(8, 8))\n",
    "pyplot.imshow(Y)\n",
    "pyplot.ylabel('Movies')\n",
    "pyplot.xlabel('Users')\n",
    "pyplot.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte del ejercicio usted trabajará con las matrices `X` y `Theta`:\n",
    "\n",
    "$$ \\text{X} = \n",
    "\\begin{bmatrix}\n",
    "- \\left(x^{(1)}\\right)^T - \\\\\n",
    "- \\left(x^{(2)}\\right)^T - \\\\\n",
    "\\vdots \\\\\n",
    "- \\left(x^{(n_m)}\\right)^T - \\\\\n",
    "\\end{bmatrix}, \\quad\n",
    "\\text{Theta} = \n",
    "\\begin{bmatrix}\n",
    "- \\left(\\theta^{(1)}\\right)^T - \\\\\n",
    "- \\left(\\theta^{(2)}\\right)^T - \\\\\n",
    "\\vdots \\\\\n",
    "- \\left(\\theta^{(n_u)}\\right)^T - \\\\\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "La fila $i$ de  `X`  corresponde al vector de atributos $x^{(i)}$  para la película $i$ y la \n",
    "fila $j$ de `Theta` corresponde a un vector paramétro $\\theta^{(j)}$ para la película $i$, y la fila\n",
    "$j$ de `Theta`  corresponde a un parámetro del vector $\\theta^{(j)}$, para el usuario $j$.\n",
    "Ambos $x^{(i)}$ y $\\theta^{(j)}$ son vectores n dimensionales. Para este ejercicio  used usará\n",
    "$n=100$, y por eso $x^{(i)} \\in \\mathbb{R}^{100}$ y $\\theta^{(j)} \\in \\mathbb{R}^{100}$.\n",
    "Correspondientemente, `X` es una matriz $n_m \\times 100$ y `Theta` es una matriz  $n_u \\times 100$.\n",
    "\n",
    "\n",
    "<a id=\"section3\"></a>\n",
    "### 2.2 Algoritmo de aprendizaje de filtros colaborativos\n",
    "\n",
    "En este momento usted comienza con la implementación del algoritmo de filtros colaborativos. Inicialmente\n",
    "implementará la función de costo (sin regularización).\n",
    "\n",
    "El algoritmo de filtros colaborativos en el contexto de recomendación de películas considera un conjunto\n",
    "n dimensional de parámetros $x^{(1)}, \\dots, x^{(n_m)}$ y $\\theta^{(1)} , \\dots, \\theta^{(n_u)}$, \n",
    "donde el modelo predice la calificación de la película $i$ por el usuario $j$ como $y^{(i,j)} = \\left( \\theta^{(j)} \\right)^T x^{(i)}$. Dado un conjunto de datos de calificaciones producido por algunos usuarios y algunas\n",
    "películas, usted desea aprender los vectores $x^{(1)}, \\dots, x^{(n_m)}, \\theta^{(1)}, \\dots, \\theta^{(n_u)}$\n",
    "que producen el mejor ajuste (minimiza el cuadrado del error). \n",
    "\n",
    "Debe completar el código en  `cofiCostFunc`  para calcular la función de costo y el gradiente de los filtros\n",
    "colaborativos. Note que los parámetros de la función (es decir, los valors que está tratando de entender)\n",
    "son `X` y `Theta`. Para poder usar un minimizador disponible tal como la función `minimize` de la librería\n",
    "`scipy`, la función de costo se postula para desarrollar los parámetros en un solo vector llamado `params`. \n",
    "Usted ha usado previamente este tipo de técnica en el ejercicio de redes neuronales.\n",
    "\n",
    "\n",
    "#### 2.2.1 Filtros colaborativos con función de costo\n",
    "\n",
    "La función de costo para filtros colaborativos (sin regularización) está dada por\n",
    "\n",
    "$$\n",
    "J(x^{(1)}, \\dots, x^{(n_m)}, \\theta^{(1)}, \\dots,\\theta^{(n_u)}) = \\frac{1}{2} \\sum_{(i,j):r(i,j)=1} \\left( \\left(\\theta^{(j)}\\right)^T x^{(i)} - y^{(i,j)} \\right)^2\n",
    "$$\n",
    "\n",
    "Usted debería \n",
    "You should now modify the function `cofiCostFunc` to return this cost in the variable `J`. Note that you should be accumulating the cost for user $j$ and movie $i$ only if `R[i,j] = 1`.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**Implementation Note**: We strongly encourage you to use a vectorized implementation to compute $J$, since it will later by called many times by `scipy`'s optimization package. As usual, it might be easiest to first write a non-vectorized implementation (to make sure you have the right answer), and the modify it to become a vectorized implementation (checking that the vectorization steps do not change your algorithm’s output). To come up with a vectorized implementation, the following tip might be helpful: You can use the $R$ matrix to set selected entries to 0. For example, `R * M` will do an element-wise multiplication between `M`\n",
    "and `R`; since `R` only has elements with values either 0 or 1, this has the effect of setting the elements of M to 0 only when the corresponding value in R is 0. Hence, `np.sum( R * M)` is the sum of all the elements of `M` for which the corresponding element in `R` equals 1.\n",
    "</div>\n",
    "\n",
    "<a id=\"cofiCostFunc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofiCostFunc(params, Y, R, num_users, num_movies,\n",
    "                      num_features, lambda_=0.0):\n",
    "    \"\"\"\n",
    "    Función de costo para filtros colaborativos\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    params : array\n",
    "        Parámetros a optimizar. Vector unidimensional\n",
    "        de tamaño (nummero de películas x número de usarios, 1).\n",
    "        Es la concatenación del vector de atributos X y los parámetros Theta.\n",
    "    \n",
    "    Y : arreglo\n",
    "        Una matriz de tamaño (num_movies x num_users) de calificaciones \n",
    "        de películas de usuarios.\n",
    "    \n",
    "    R : arreglo\n",
    "        Una matriz (num_movies x num_users) matrix, donde R[i, j] = 1 si la\n",
    "        película i fue calificada por el usuario j.\n",
    "    \n",
    "    num_users : int\n",
    "        Número total de usuarios.\n",
    "    \n",
    "    num_movies : int\n",
    "        Número total de películas.\n",
    "    \n",
    "    num_features : int\n",
    "        Número de atributos a aprender\n",
    "    \n",
    "    lambda_ : float, opcional\n",
    "        Coeficiente de regularización\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    J : float\n",
    "        Valor de la función de costo para los parámetros datos. \n",
    "    \n",
    "    grad : arreglo\n",
    "        Gradiente del vector de costo como función de los parámetros.\n",
    "        Tiene tamaño   (num_movies x num_users, 1).\n",
    "    \n",
    "    Instrucciones\n",
    "    ------------\n",
    "    Calcula la función de costo y su gradiente de los filtros colaborativos.\n",
    "    Concretamente, debe implementar primero la función de costo (sin \n",
    "    regularización) y verificar que se ajusta a nuestros costos. Luego \n",
    "    debe implementar el gradiente correctamente. Finalmente, debe implementar\n",
    "    la parte de la regularización.\n",
    "    \n",
    "    \n",
    "    Notas\n",
    "    -----\n",
    "    - Los parámetros se reparten en dos matrices:\n",
    "        X : matriz de tamaño (num_movies  x num_features) con los atributos\n",
    "        Theta : de tamañp (num_users  x num_features) con los atributos de usuario\n",
    "\n",
    "    - Debe asignar las siguientes variables correctamente:\n",
    "\n",
    "        X_grad : matriz de tamaño (num_movies x num_features) con \n",
    "                 derivadas parciales con respecto a cada elemento de X\n",
    "        Theta_grad : matrix de tamaño (num_users x num_features) con\n",
    "                     derivadas parciales con respecto a cada elemento de Theta\n",
    "\n",
    "    - El gradiente de retorno es la concatenación de los gradientes\n",
    "      de X,  X_grad and Theta, Theta_grad.\n",
    "    \"\"\"\n",
    "    # Depliege las matrices U y W de los parámetros\n",
    "    X = params[:num_movies*num_features].reshape(num_movies, num_features)\n",
    "    Theta = params[num_movies*num_features:].reshape(num_users, num_features)\n",
    "\n",
    "    # Debe retornar las siguientes variables correctamente\n",
    "    J = 0\n",
    "    X_grad = np.zeros(X.shape)\n",
    "    Theta_grad = np.zeros(Theta.shape)\n",
    "\n",
    "    # ====================== Su Código Acá ======================\n",
    "\n",
    "    \n",
    "    \n",
    "    # =============================================================\n",
    "    \n",
    "    grad = np.concatenate([X_grad.ravel(), Theta_grad.ravel()])\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de completar la función, la celda siguiente corre la función de costo. Para ayudarle a depurar la función de costo, incluimos un conjunto de pesos previamente entrenados. Debe esperar, como salida 22.22.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Cargue los pesos pre-entrenados (X, Theta, num_users, num_movies, num_features)\n",
    "data = loadmat(os.path.join('Data', 'ex8_movieParams.mat'))\n",
    "X, Theta, num_users, num_movies, num_features = data['X'],\\\n",
    "        data['Theta'], data['num_users'], data['num_movies'], data['num_features']\n",
    "\n",
    "#  Reduzca los datos para que el programa corra más rápido\n",
    "num_users = 4\n",
    "num_movies = 5\n",
    "num_features = 3\n",
    "\n",
    "X = X[:num_movies, :num_features]\n",
    "Theta = Theta[:num_users, :num_features]\n",
    "Y = Y[:num_movies, 0:num_users]\n",
    "R = R[:num_movies, 0:num_users]\n",
    "\n",
    "#  Evalúe la función de costo\n",
    "J, _ = cofiCostFunc(np.concatenate([X.ravel(), Theta.ravel()]),\n",
    "                    Y, R, num_users, num_movies, num_features)\n",
    "           \n",
    "print('Cost at loaded parameters:  %.2f \\n(this value should be about 22.22)' % J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "#### 2.2.2 Gradiente de filtros colaborativos\n",
    "\n",
    "En este punto debe implementar el gradiente (sin regularización). Específicamente, usted debería completar\n",
    "el código `cofiCostFunc` que retorna las variables `X_grad` y `Theta_grad`.  Note que `X_grad` debe ser\n",
    "una matriz del mismo tamaño que `X` y similarmente, `Theta_grad` es una matriz del mismo tamaño que\n",
    "`Theta`.  Los gradientes de la función de costo están dados por:\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial x_k^{(i)}} = \\sum_{j:r(i,j)=1} \\left( \\left(\\theta^{(j)}\\right)^T x^{(i)} - y^{(i,j)} \\right) \\theta_k^{(j)} $$\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial \\theta_k^{(j)}} = \\sum_{i:r(i,j)=1} \\left( \\left(\\theta^{(j)}\\right)^T x^{(i)}- y^{(i,j)} \\right) x_k^{(i)} $$\n",
    "\n",
    "\n",
    "Note que la función retorna el gradiente para ambos conjuntos de variables plegándolos en un solo vector.\n",
    "Luego de completar el código para calcular los gradientes, la próxima celda le permite verificar el gradiente\n",
    "(disponible en `utils.checkCostFunction`) mediante la verificación de la implementación de sus gradientes\n",
    "(esto es similar al chequeo numérico que se usó en el ejercicio de redes neuronales). Si su implementación\n",
    "es correcta, usted debería encontrar que el gradiente analítico y numérico deben estar cerca. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "**Nota de Imlementación**: Puede obtener crédito total sin usar una implementación vectorizada, solo que\n",
    "su código correrá mucho mas lento (un poco número de horas), de forma que recomendamos que trate de \n",
    "vectorizar su implementación. Para comenzar, usted puede implementar el gradiente con un ciclo °for°\n",
    "sobre películas (para calcular  $\\frac{\\partial J}{\\partial x^{(i)}_k}$) y un ciclo \"for\" sobre \n",
    "usuarios (para calcular $\\frac{\\partial J}{\\theta_k^{(j)}}$). Cuando implemente el gradiente inicialmente,\n",
    "podría comenzar con una implementación no vectorizada, mediante la implementación de un ciclo \"for\" que calcula\n",
    "cada elemento de la suma. Luego puede tratar de vectorizar su implementación (vectorice los ciclos internos \"for\"),\n",
    "de forma que solo termina con dos ciclos \"for\" (uno sobre las películas para calcular $\\frac{\\partial J}{\\partial x_k^{(i)}}$ para cada película, y otro ciclo \"for\" sobre usuarios para calcular $\\frac{\\partial J}{\\partial \\theta_k^{(j)}}$ por usuario.\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "**Sugerencia de Implementación:**  Para implementar la vectorización podría ser útil la búsqueda\n",
    "una forma de calcular todas las derivadas asociadas con $x_1^{(i)} , x_2^{(i)}, \\dots , x_n^{(i)}$ \n",
    "(es decir, los términos derivados asociados con el vector de atributos  $x^{(i)}$) al mismo tiempo.\n",
    "Definamos las derivadas del vector de atributos de la película $i$:\n",
    "    \n",
    "\n",
    "$$ \\left(X_{\\text{grad}} \\left(i, :\\right)\\right)^T = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial J}{\\partial x_1^{(i)}} \\\\\n",
    "\\frac{\\partial J}{\\partial x_2^{(i)}} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial J}{\\partial x_n^{(i)}}\n",
    "\\end{bmatrix} = \\quad\n",
    "\\sum_{j:r(i,j)=1} \\left( \\left( \\theta^{(j)} \\right)^T x^{(i)} - y^{(i,j)} \\right) \\theta^{(j)}\n",
    "$$\n",
    "\n",
    "Para vectorizar la expresión de arriba puede comenzar con indizar `Theta` y `Y` para seleccionar solo\n",
    "los elementos de interés (es decir, `r[i, j] = 1`).  Intuitivamente, cuando considere los atributos\n",
    "para la película $i$, solo se debe preocupar por usuarios que han calificado la película, esto le permite\n",
    "remover todos los usuarios de Theta` y `Y`. <br/><br/>\n",
    "\n",
    "\n",
    "Concretely, you can set `idx = np.where(R[i, :] == 1)[0]` to be a list of all the users that have rated movie $i$. This will allow you to create the temporary matrices `Theta_temp = Theta[idx, :]` and `Y_temp = Y[i, idx]` that index into `Theta` and `Y` to give you only the set of users which have rated the $i^{th}$ movie. This will allow you to write the derivatives as: <br>\n",
    "\n",
    "`X_grad[i, :] = np.dot(np.dot(X[i, :], Theta_temp.T) - Y_temp, Theta_temp)`\n",
    "\n",
    "<br><br>\n",
    "Note que la versión vectorizada de arriba retorna un vector fila. Luego de vectorizar sus cálculos\n",
    "de las derivadas con respecto a $x^{(i)}$,, debe usar un método similar para vectorizar las derivadas\n",
    "con respecto a  $θ^{(j)}$ \n",
    "</div>\n",
    "\n",
    "\n",
    "[Haga click acá para regresar a la función `cofiCostFunc` y actualizarla](#cofiCostFunc). \n",
    "\n",
    "<font color=\"red\"> No olvide ejecutar de nuevo la celda que contiene la función  `cofiCostFunc` \n",
    "de forma que se actualice con la implementación del cómputo del gradiente </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Verifique los gradientes corriendo checkcostFunction\n",
    "utils.checkCostFunction(cofiCostFunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "#### 2.2.3 Función de costo regularizada.\n",
    "\n",
    "La función de costo para el gradiente colaborativo con regularización es\n",
    "\n",
    "$$ J(x^{(1)}, \\dots, x^{(n_m)}, \\theta^{(1)}, \\dots, \\theta^{(n_u)}) = \\frac{1}{2} \\sum_{(i,j):r(i,j)=1} \\left( \\left( \\theta^{(j)} \\right)^T x^{(i)} - y^{(i,j)} \\right)^2 + \\left( \\frac{\\lambda}{2} \\sum_{j=1}^{n_u} \\sum_{k=1}^{n} \\left( \\theta_k^{(j)} \\right)^2  \\right) + \\left( \\frac{\\lambda}{2} \\sum_{i=1}^{n_m} \\sum_{k=1}^n \\left(x_k^{(i)} \\right)^2 \\right) $$\n",
    "\n",
    "Debe agregar regularización a los cálculos originales de la función de costo,  $J$. Luego de esto,\n",
    "la próxima celda corre su función regularizada, y usted debería esperar que la función de costo\n",
    "produzca  un valor  de 31.34.\n",
    "\n",
    "\n",
    "[Haga click acá para regresar a  `cofiCostFunc` y actualizarla](#cofiCostFunc)\n",
    "<font color=\"red\"> No olvide volver a ejecutar la celda que contiene la funci[on de costo `cofiCostFunc`\n",
    "de forma que se actualice en su implementación de costo regularizada. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Evalúe la función de costo\n",
    "J, _ = cofiCostFunc(np.concatenate([X.ravel(), Theta.ravel()]),\n",
    "                    Y, R, num_users, num_movies, num_features, 1.5)\n",
    "           \n",
    "print('Cost at loaded parameters (lambda = 1.5): %.2f' % J)\n",
    "print('              (this value should be about 31.34)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section6\"></a>\n",
    "#### 2.2.4 Gradiente Regularizado\n",
    "\n",
    "Ahora que ha implementado la función de costo regularizada debe proceder a implementar la regularización del\n",
    "gradiente. Debe agregar a su implementación la función `cofiCostFunc` que retorna el gradiente regularizado\n",
    "al agregar la contribución de los términos de regularización.   Note que los gradientes de la función \n",
    "de costo con regularización están datos por\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial x_k^{(i)}} = \\sum_{j:r(i,j)=1} \\left( \\left(\\theta^{(j)}\\right)^T x^{(i)} - y^{(i,j)} \\right) \\theta_k^{(j)} + \\lambda x_k^{(i)} $$\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial \\theta_k^{(j)}} = \\sum_{i:r(i,j)=1} \\left( \\left(\\theta^{(j)}\\right)^T x^{(i)}- y^{(i,j)} \\right) x_k^{(i)} + \\lambda \\theta_k^{(j)} $$\n",
    "\n",
    "\n",
    "Esto significa que usted debe agregar  $\\lambda x^{(i)}$ a la variable  `X_grad[i,:]`  descrita anteriormente,\n",
    "y agregar $\\lambda \\theta^{(j)}$ a la variable `Theta_grad[j, :]` descrita anteriormente. \n",
    "\n",
    "\n",
    "[Haga click acá para regresar a  `cofiCostFunc` y actualizarla](#cofiCostFunc)\n",
    "<font color=\"red\"> No olvide volver a ejecutar la celda que contiene la función `cofiCostFunc`  para actualizar\n",
    "su implementación con gradiente de función regularizada.</font>\n",
    "\n",
    "Luego de completar el código para calcular los gradientes, la próxima celda corre otro gradiente\n",
    "para verificar (`utils.checkCostFunction`) que su implementación numérica es correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Verifique los gradientes al correr checkCostFunction\n",
    "utils.checkCostFunction(cofiCostFunc, 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Aprendizaje de recomendaciones de películas\n",
    "\n",
    "Luego de terminar la implementación de las funciones de costo y gradiente de filtros colaborativos, \n",
    "debe comenzar el entrenamiento del algoritmo para sugerir recomendaciones para usted mismo. En la\n",
    "próxima celda, usted puede ingresar sus propia preferencias de forma que, cuando el algoritmo corre, \n",
    "pueda obtener recomendaciones!  Hemos llenado algunos valores con nuestras preferencias. Sin embargo\n",
    "usted debe cambiar esto de acuerdo a sus gustos. La lista de todas las películas y su número en los datos\n",
    "puede ser encontrada en el archivo `Data/movie_idx.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Antes de entrenar el modelo de filtros colaborativos primero\n",
    "#  agregatmos calificaciones que corresponden a un nuevo usuario que\n",
    "#  acabamos de observar.  Esta parte del código también te permite\n",
    "#  agregar sus propias calificaciones para los datos de películas.\n",
    "movieList = utils.loadMovieList()\n",
    "n_m = len(movieList)\n",
    "\n",
    "#  inicialice mis calificaciones\n",
    "my_ratings = np.zeros(n_m)\n",
    "\n",
    "# Verifique el archivo movie_idx.txt para id de cada película en los datos\n",
    "# For ejemplo, Toy Story (1995) tiene un ID de 1, y una calificación de 4. \n",
    "# Note que el índice es ID-1, dado que comenzamos con un índice 0.\n",
    "my_ratings[0] = 4\n",
    "\n",
    "# O suponga que no le gustó Silence of the Lambs (1991), la puedes asignar.\n",
    "my_ratings[97] = 2\n",
    "\n",
    "# Seleccionamos unas pocas películas que nos gustan / o no con calificaciones\n",
    "my_ratings[6] = 3\n",
    "my_ratings[11]= 5\n",
    "my_ratings[53] = 4\n",
    "my_ratings[63] = 5\n",
    "my_ratings[65] = 3\n",
    "my_ratings[68] = 5\n",
    "my_ratings[182] = 4\n",
    "my_ratings[225] = 5\n",
    "my_ratings[354] = 5\n",
    "\n",
    "print('New user ratings:')\n",
    "print('-----------------')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print('Rated %d stars: %s' % (my_ratings[i], movieList[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Recomendaciones\n",
    "\n",
    "Luego de las que calificaciones adicionales  han sido añadidas al conjunto,\n",
    "el programa procede a entrenar el modelo de filtros colaborativos. Este aprende\n",
    "los parámetros X y Theta. Para predecir las calificaciones de la película i \n",
    "para el usuario j, necesita calcular (0 (j) ) T x (i). \n",
    "La próxima parte del programa calcula las calificaciones para todas las películas\n",
    "y usuarios y muestra las películas recomendadas (Figura 4), de acuerdo\n",
    "a las calificaciones que fueron agregadas anteriormente. Note que\n",
    "usted puede obtener un conjunto diferente de predicciones debido a las\n",
    "inicializaciones aleatorias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Ahora entrenamos un modelo de filtros colaborativos en calificación de películas\n",
    "#  conjunto de  1682 películas y 943 usuarios\n",
    "\n",
    "#  cargue los datos\n",
    "data = loadmat(os.path.join('Data', 'ex8_movies.mat'))\n",
    "Y, R = data['Y'], data['R']\n",
    "\n",
    "#  Y es una matriz  1682x943 con calificaciones (1-5) de 1682 películas\n",
    "#  y 943 usuarios\n",
    "\n",
    "#  R es una matriz 1682x943 matrix, donde R(i,j) = 1 si y solo si el  usuario j califica\n",
    "#  la película i\n",
    "\n",
    "#  agrege us propias calificaciones a la matriz de datos\n",
    "Y = np.hstack([my_ratings[:, None], Y])\n",
    "R = np.hstack([(my_ratings > 0)[:, None], R])\n",
    "\n",
    "#  normalice las calificaciones\n",
    "Ynorm, Ymean = utils.normalizeRatings(Y, R)\n",
    "\n",
    "#  valores útiles\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 10\n",
    "\n",
    "# conjunto de parámetros iniciales (Theta, X)\n",
    "X = np.random.randn(num_movies, num_features)\n",
    "Theta = np.random.randn(num_users, num_features)\n",
    "\n",
    "initial_parameters = np.concatenate([X.ravel(), Theta.ravel()])\n",
    "\n",
    "# Establezca opciones para scipy.optimize.minimize\n",
    "options = {'maxiter': 100}\n",
    "\n",
    "# Establezca la regularización\n",
    "lambda_ = 10\n",
    "res = optimize.minimize(lambda x: cofiCostFunc(x, Ynorm, R, num_users,\n",
    "                                               num_movies, num_features, lambda_),\n",
    "                        initial_parameters,\n",
    "                        method='TNC',\n",
    "                        jac=True,\n",
    "                        options=options)\n",
    "theta = res.x\n",
    "\n",
    "# Despliege la matriz retornada theta en U y W\n",
    "X = theta[:num_movies*num_features].reshape(num_movies, num_features)\n",
    "Theta = theta[num_movies*num_features:].reshape(num_users, num_features)\n",
    "\n",
    "print('Recommender system learning completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de entrenar el modelo puede hacer recomendaciones para calcular la matriz de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.dot(X, Theta.T)\n",
    "my_predictions = p[:, 0] + Ymean\n",
    "\n",
    "movieList = utils.loadMovieList()\n",
    "\n",
    "ix = np.argsort(my_predictions)[::-1]\n",
    "\n",
    "print('Top recommendations for you:')\n",
    "print('----------------------------')\n",
    "for i in range(10):\n",
    "    j = ix[i]\n",
    "    print('Predicting rating %.1f for movie %s' % (my_predictions[j], movieList[j]))\n",
    "\n",
    "print('\\nOriginal ratings provided:')\n",
    "print('--------------------------')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print('Rated %d for %s' % (my_ratings[i], movieList[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
